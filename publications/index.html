<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge">

  <title>INDE lab | publications</title>
  <meta name="description" content="The Intelligent Data Engineering Lab (INDE lab) at the University of Amsterdam">

  <link rel="shortcut icon" href="/assets/img/favicon.ico">

  <link rel="stylesheet" href="/assets/css/main.css">
  <link rel="canonical" href="/publications/">
</head>


  <body>

    <header class="site-header">

  <div class="wrapper">  
    

    <nav class="site-nav">
      <input type="checkbox" id="nav-trigger" class="nav-trigger">
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewbox="0 0 18 15" width="18px" height="15px">
              <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"></path>
              <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"></path>
              <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"></path>
            </svg>
          </span>
        </label>

      <div class="trigger">
        <!-- About -->
        <a class="page-link" href="/">about</a>

        <!-- Blog
        <a class="page-link" href="/blog/">blog</a>  -->

        <!-- Pages -->
        
          
        
          
        
          
            <a class="page-link" href="/news/">news</a>
          
        
          
            <a class="page-link" href="/people/">people</a>
          
        
          
            <a class="page-link" href="/projects/">projects</a>
          
        
          
            <a class="page-link" href="/publications/">publications</a>
          
        
          
            <a class="page-link" href="/resources/">data &amp; software</a>
          
        
          
        

        <!-- CV link -->
        <!-- <a class="page-link" href="/assets/pdf/CV.pdf">vitae</a> -->

      </div>
    </nav>

  </div>

</header>



    <div class="page-content">
      <div class="wrapper">
        <div class="post">

  <header class="post-header">
    <h1 class="post-title">publications</h1>
    <h5 class="post-description">Selected recent publications. Generated by jekyll-scholar.</h5>
  </header>

  <article class="post-content publications clearfix">
    

<p><a href="https://github.com/pgroth/INDElab/blob/master/_bibliography/papers.bib">Bibtex file</a> with the publications listed below.</p>

<h3 class="year">2025</h3>
<ol class="bibliography">
<li>

<div id="pmlr-v284-allen25a">
  
    <span class="title">Sound and Complete Neurosymbolic Reasoning with LLM-Grounded Interpretations</span>
    <span class="author">
      
        
          
            
              
                Bradley P. Allen,
              
            
          
        
      
        
          
            
              
                Prateek Chhikara,
              
            
          
        
      
        
          
            
              
                Thomas Macaulay Ferguson,
              
            
          
        
      
        
          
            
              
                Filip Ilievski,
              
            
          
        
      
        
          
            
              
                and Paul Groth
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Proceedings of The 19th International Conference on Neurosymbolic Learning and Reasoning</em>
    
    
      2025
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
  
    [<a href="https://proceedings.mlr.press/v284/allen25a.html" target="_blank">Link</a>]
  
  
  
  
  
  
    [<a href="https://github.com/bradleypallen/bilateral-factuality-evaluation" target="_blank">Code</a>]
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Large language models (LLMs) have demonstrated impressive capabilities in natural language understanding and generation, but they exhibit problems with logical consistency in the output they generate. How can we harness LLMs’ broad-coverage parametric knowledge in formal reasoning despite their inconsistency? We present a method for directly integrating an LLM into the interpretation function of the formal semantics for a paraconsistent logic. We provide experimental evidence for the feasibility of the method by evaluating the function using datasets created from several short-form factuality benchmarks. Unlike prior work, our method offers a theoretical framework for neurosymbolic reasoning that leverages an LLM’s knowledge while preserving the underlying logic’s soundness and completeness properties.</p>
  </span>
  
</div>
</li>
<li>

<div id="pmlr-v284-karabulut25a">
  
    <span class="title">Neurosymbolic Association Rule Mining from Tabular Data</span>
    <span class="author">
      
        
          
            
              
                Erkan Karabulut,
              
            
          
        
      
        
          
            
              
                Paul Groth,
              
            
          
        
      
        
          
            
              
                and Victoria Degeler
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Proceedings of The 19th International Conference on Neurosymbolic Learning and Reasoning</em>
    
    
      2025
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
  
    [<a href="https://proceedings.mlr.press/v284/karabulut25a.html" target="_blank">Link</a>]
  
  
  
  
  
  
    [<a href="https://github.com/DiTEC-project/aerial-rule-mining" target="_blank">Code</a>]
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Association Rule Mining (ARM) is the task of mining patterns among data features in the form of logical rules, with applications across a myriad of domains. However, high-dimensional datasets often result in an excessive number of rules, increasing execution time and negatively impacting downstream task performance. Managing this rule explosion remains a central challenge in ARM research. To address this, we introduce Aerial+, a novel neurosymbolic ARM method. Aerial+ leverages an under-complete autoencoder to create a neural representation of the data, capturing associations between features. It extracts rules from this neural representation by exploiting the model’s reconstruction mechanism. Extensive evaluations on five datasets against seven baselines demonstrate that Aerial+ achieves state-of-the-art results by learning more concise, high-quality rule sets with full data coverage. When integrated into rule-based interpretable machine learning models, Aerial+ significantly reduces execution time while maintaining or improving accuracy.</p>
  </span>
  
</div>
</li>
<li>

<div id="doi:10.1177/29498732251377518">
  
    <span class="title">Learning Semantic Association Rules from Internet of Things Data</span>
    <span class="author">
      
        
          
            
              
                Erkan Karabulut,
              
            
          
        
      
        
          
            
              
                Paul Groth,
              
            
          
        
      
        
          
            
              
                and Victoria Degeler
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>Neurosymbolic Artificial Intelligence</em>
    
    
      2025
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
  
    [<a href="https://doi.org/10.1177/29498732251377518" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.1177/29498732251377518" target="_blank">DOI:10.1177/29498732251377518</a>]
  
  
  
  
  
    [<a href="https://github.com/DiTEC-project/semantic-association-rule-learning" target="_blank">Code</a>]
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p> Association rule mining (ARM) is the task of discovering commonalities in data in the form of logical implications. ARM is used in the Internet of Things (IoT) for different tasks, including monitoring and decision-making. However, existing methods give limited consideration to IoT-specific requirements such as heterogeneity and volume. Furthermore, they do not utilize important static domain-specific description data about IoT systems, which is increasingly represented as knowledge graphs. In this paper, we propose a novel ARM pipeline for IoT data that utilizes both dynamic sensor data and static IoT system metadata. Furthermore, we propose an autoencoder-based neurosymbolic ARM method (Aerial) as part of the pipeline to address the high volume of IoT data and reduce the total number of rules that are resource-intensive to process. Aerial learns a neural representation of a given dataset and extracts association rules from this representation by exploiting the reconstruction (decoding) mechanism of an autoencoder. Extensive evaluations on three IoT datasets from two domains show that ARM on both static and dynamic IoT data results in more generically applicable rules while Aerial can learn a more concise set of high-quality association rules than the state-of-the-art, with full coverage over the datasets. </p>
  </span>
  
</div>
</li>
<li>

<div id="10.14778/3750601.3750671">
  
    <span class="title">mlidea: Interactively Improving ML Data Preparation Code via "Shadow Pipelines"</span>
    <span class="author">
      
        
          
            
              
                Stefan Grafberger,
              
            
          
        
      
        
          
            
              
                Paul Groth,
              
            
          
        
      
        
          
            
              
                and Sebastian Schelter
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>Proc. VLDB Endow.</em>
    
    
      2025
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
  
    [<a href="https://doi.org/10.14778/3750601.3750671" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.14778/3750601.3750671" target="_blank">DOI:10.14778/3750601.3750671</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Data scientists develop ML pipelines in an iterative manner: they repeatedly screen a pipeline for potential issues, debug it, and then revise and improve its code according to their findings. However, this manual process is tedious and error-prone. To address this challenge, we propose to assist data scientists with automatically derived interactive suggestions for pipeline improvements during this development cycle. We demonstrate mlidea, a library to generate interactive suggestions with so-called shadow pipelines, hidden variants of the original pipeline that modify it to auto-detect potential issues, try out modifications for improvements, and suggest and explain these modifications to the user. Our system uses incremental view maintenance to enable data scientists to quickly iterate on their code and to ensure low-latency maintenance of the shadow pipelines. We demonstrate how our system improves code for various domains with three interactive shadow pipelines: fixing mislabeled rows, enhancing robustness against data quality problems, and improving pipeline performance on data slices with subpar predictions.</p>
  </span>
  
</div>
</li>
<li>

<div id="KARABULUT2025102341">
  
    <span class="title">PyAerial: Scalable association rule mining from tabular data</span>
    <span class="author">
      
        
          
            
              
                Erkan Karabulut,
              
            
          
        
      
        
          
            
              
                Paul Groth,
              
            
          
        
      
        
          
            
              
                and Victoria Degeler
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>SoftwareX</em>
    
    
      2025
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
  
    [<a href="https://doi.org/10.1016/j.softx.2025.102341" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.1016/j.softx.2025.102341" target="_blank">DOI:10.1016/j.softx.2025.102341</a>]
  
  
  
  
  
    [<a href="https://github.com/DiTEC-project/pyaerial" target="_blank">Code</a>]
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Association Rule Mining (ARM) is a knowledge discovery technique that identifies frequent patterns as logical implications within transaction datasets and has been applied across domains such as e-commerce, healthcare, and cyber–physical systems. However, many state-of-the-art ARM methods, typically algorithmic or nature-inspired, suffer from rule explosion and long execution times. Aerial is a novel neurosymbolic ARM algorithm for tabular datasets that mitigates rule explosion using neural networks, while remaining compatible with existing approaches. Aerial transforms tables into transactions, uses an autoencoder to learn compact neural representations, and extracts logical rules from the neural representations. This paper presents PyAerial, a Python library that makes Aerial accessible and easy to use on generic tabular datasets for end users in a domain-independent way. Besides association rules, PyAerial can also be used to extract frequent itemsets, learn classification rules, apply item constraints to learn rules over the features of interest rather than all features, pre-discretize numerical data for ARM, and can be run on a GPU.</p>
  </span>
  
</div>
</li>
<li>

<div id="LI2026129643">
  
    <span class="title">A survey of large language models for data challenges in graphs</span>
    <span class="author">
      
        
          
            
              
                Mengran Li,
              
            
          
        
      
        
          
            
              
                Pengyu Zhang,
              
            
          
        
      
        
          
            
              
                Wenbin Xing,
              
            
          
        
      
        
          
            
              
                Yijia Zheng,
              
            
          
        
      
        
          
            
              
                Klim Zaporojets,
              
            
          
        
      
        
          
            
              
                Junzhou Chen,
              
            
          
        
      
        
          
            
              
                Ronghui Zhang,
              
            
          
        
      
        
          
            
              
                Yong Zhang,
              
            
          
        
      
        
          
            
              
                Siyuan Gong,
              
            
          
        
      
        
          
            
              
                Jia Hu,
              
            
          
        
      
        
          
            
              
                Xiaolei Ma,
              
            
          
        
      
        
          
            
              
                Zhiyuan Liu,
              
            
          
        
      
        
          
            
              
                Paul Groth,
              
            
          
        
      
        
          
            
              
                and Marcel Worring
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>Expert Systems with Applications</em>
    
    
      2025
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
    [<a href="http://arxiv.org/abs/https://arxiv.org/abs/2505.18475" target="_blank">arXiv</a>]
  
  
  
  
    [<a href="https://www.sciencedirect.com/science/article/pii/S0957417425032580" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/https://doi.org/10.1016/j.eswa.2025.129643" target="_blank">DOI:https://doi.org/10.1016/j.eswa.2025.129643</a>]
  
  
  
  
  
    [<a href="https://github.com/limengran98/Awesome-Literature-Graph-Learning-Challenges" target="_blank">Code</a>]
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Graphs are a widely used paradigm for representing non-Euclidean data, with applications ranging from social network analysis to biomolecular prediction. While graph learning has achieved remarkable progress, real-world graph data presents a number of challenges that significantly hinder the learning process. In this survey, we focus on four fundamental data-centric challenges: (1) Incompleteness, real-world graphs have missing nodes, edges, or attributes; (2) Imbalance, the distribution of the labels of nodes or edges and their structures for real-world graphs are highly skewed; (3) Cross-domain Heterogeneity, graphs from different domains exhibit incompatible feature spaces or structural patterns; and (4) Dynamic Instability, graphs evolve over time in unpredictable ways. Recently, Large Language Models (LLMs) offer the potential to tackle these challenges by leveraging rich semantic reasoning and external knowledge. This survey focuses on how LLMs can address four fundamental data-centric challenges in graph-structured data, thereby improving the effectiveness of graph learning. For each challenge, we review both traditional solutions and modern LLM-driven approaches, highlighting how LLMs contribute unique advantages. Finally, we discuss open research questions and promising future directions in this emerging interdisciplinary field. To support further exploration, we have curated a repository of recent advances on graph learning challenges: https://github.com/limengran98/Awesome-Literature-Graph-Learning-Challenges.</p>
  </span>
  
</div>
</li>
<li>

<div id="jackson2025basil">
  
    <span class="title">BASIL DB: bioactive semantic integration and linking database</span>
    <span class="author">
      
        
          
            
              
                David Jackson,
              
            
          
        
      
        
          
            
              
                Paul Groth,
              
            
          
        
      
        
          
            
              
                and Hazar Harmouch
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>Journal of Biomedical Semantics</em>
    
    
      2025
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="https://doi.org/10.1186/s13326-025-00336-3" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.1186/s13326-025-00336-3" target="_blank">DOI:10.1186/s13326-025-00336-3</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="Harper22082025">
  
    <span class="title">The Librarian Skillset and the Needs of Artificial Intelligence</span>
    <span class="author">
      
        
          
            
              
                Corey Harper,
              
            
          
        
      
        
          
            
              
                and Paul Groth
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>Cataloging &amp; Classification Quarterly</em>
    
    
      2025
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="https://doi.org/10.1080/01639374.2025.2539787%0A" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.1080/01639374.2025.2539787" target="_blank">DOI:10.1080/01639374.2025.2539787</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="10.1007/978-3-031-94575-5_20">
  
    <span class="title">Designing Hierarchies for Optimal Hyperbolic Embedding</span>
    <span class="author">
      
        
          
            
              
                Melika Ayoughi,
              
            
          
        
      
        
          
            
              
                Max Spengler,
              
            
          
        
      
        
          
            
              
                Pascal Mettes,
              
            
          
        
      
        
          
            
              
                and Paul Groth
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Proceedings of the 22nd European Semantic Web Conference (ESWC)</em>
    
    
      2025
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
  
    [<a href="http://melika.xyz/data/eswc_paper.pdf" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.1007/978-3-031-94575-5_20" target="_blank">DOI:10.1007/978-3-031-94575-5_20</a>]
  
  
  
  
  
    [<a href="https://github.com/Melika-Ayoughi/Optimal-Hierarchy" target="_blank">Code</a>]
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Hyperbolic geometry has shown to be highly effective for embedding hierarchical data structures. As such, machine learning in hyperbolic space is rapidly gaining traction across a wide range of disciplines, from recommender systems and graph networks to biological systems and computer vision. The performance of hyperbolic learning commonly depends on the hierarchical information used as input or supervision. Given that knowledge graphs and ontologies are common sources of such hierarchies, this paper aims to guide ontology designers in designing hierarchies for use in these learning algorithms. Using widely employed measures of embedding quality with extensive experiments, we find that hierarchies are best suited for hyperbolic embeddings when they are wide, and single inheritance, independent of the hierarchy size and imbalance.</p>
  </span>
  
</div>
</li>
<li>

<div id="sigmodrecrod2025">
  
    <span class="title">The Five Facets of Data Quality Assessment</span>
    <span class="author">
      
        
          
            
              
                Sedir Mohammed,
              
            
          
        
      
        
          
            
              
                Lisa Ehrlinger,
              
            
          
        
      
        
          
            
              
                Hazar Harmouch,
              
            
          
        
      
        
          
            
              
                Felix Naumann,
              
            
          
        
      
        
          
            
              
                and  Divesh Srivastava
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>SIGMOD Record</em>
    
    
      2025
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="https://sigmodrecord.org/publications/sigmodRecord/2506/pdfs/04_Vision_Mohammed.pdf" target="_blank">Link</a>]
  
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="Li2025">
  
    <span class="title">Evaluation of unsupervised static topic models’ emergence detection ability</span>
    <span class="author">
      
        
          
            
              
                Xue Li,
              
            
          
        
      
        
          
            
              
                Ciro D. Esposito,
              
            
          
        
      
        
          
            
              
                Paul Groth,
              
            
          
        
      
        
          
            
              
                Jonathan Sitruk,
              
            
          
        
      
        
          
            
              
                Balazs Szatmari,
              
            
          
        
      
        
          
            
              
                and Nachoem Wijnberg
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>PeerJ Computer Science</em>
    
    
      2025
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="http://dx.doi.org/10.7717/peerj-cs.2875" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.7717/peerj-cs.2875" target="_blank">DOI:10.7717/peerj-cs.2875</a>]
  
  
  
  
  
  
    [<a href="https://zenodo.org/records/14503316" target="_blank">Data</a>]
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="10.7717/peerj-cs.2793">
  
    <span class="title">The effects of mismatched train and test data cleaning pipelines on regression models: lessons for practice</span>
    <span class="author">
      
        
          
            
              
                James Nevin,
              
            
          
        
      
        
          
            
              
                Michael Lees,
              
            
          
        
      
        
          
            
              
                and Paul Groth
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>PeerJ Computer Science</em>
    
    
      2025
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
  
    [<a href="https://doi.org/10.7717/peerj-cs.2793" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.7717/peerj-cs.2793" target="_blank">DOI:10.7717/peerj-cs.2793</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>
    Data quality problems are present in all real-world, large-scale datasets. Each of these potential problems can be addressed in multiple ways through data cleaning. However, there is no single best data cleaning approach that always produces a perfect result, meaning that a choice needs to be made about which approach to use. At the same time, machine learning (ML) models are being trained and tested on these cleaned datasets, usually with one single data cleaning pipeline applied. In practice, however, data cleaning pipelines are updated regularly, often without retraining of production models. It is therefore common to apply different test (or production) data than the data on which the models were originally trained. The changes in these new test data and the data cleaning process applied can have potential ramifications for model performance. In this article, we show the impact that altering a data cleaning pipeline between the training and testing steps of an ML workflow can have. Through the fitting and evaluation of over 6,000 models, we find that mismatches between cleaning pipelines on training and test data can have a meaningful impact on regression model performance. Counter-intuitively, such mismatches can improve test set performance and potentially alter model selection choices.
    </p>
  </span>
  
</div>
</li>
<li>

<div id="Borgman2025From">
  
    <span class="title">From Data Creator to Data Reuser: Distance Matters</span>
    <span class="author">
      
        
          
            
              
                Christine L. Borgman,
              
            
          
        
      
        
          
            
              
                and Paul Groth
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>Harvard Data Science Review</em>
    
    
      2025
    
    </span>
  

  <span class="links">
  
  
  
  
  
  
    [<a href="http://doi.org/10.1162/99608f92.35d32cfc" target="_blank">DOI:10.1162/99608f92.35d32cfc</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="Borgman2025Infrastructure">
  
    <span class="title">Infrastructure, Intermediaries, and Artificial Intelligence: A Rejoinder to Commentaries on “From Data Creator to Data Reuser: Distance Matters"</span>
    <span class="author">
      
        
          
            
              
                Christine L. Borgman,
              
            
          
        
      
        
          
            
              
                and Paul Groth
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>Harvard Data Science Review</em>
    
    
      2025
    
    </span>
  

  <span class="links">
  
  
  
  
  
  
    [<a href="http://doi.org/10.1162/99608f92.c17c3adb" target="_blank">DOI:10.1162/99608f92.c17c3adb</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="reyesphd">
  
    <span class="title">FAIR Research Objects and computational workflows</span>
    <span class="author">
      
        
          
            Stian Soiland-Reyes
          
        
      
    </span>

    <span class="periodical">
    
    
      2025
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
  
    [<a href="https://pure.uva.nl/ws/files/210878984/Thesis.pdf" target="_blank">Link</a>]
  
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>This PhD thesis explores the topics of RO-Crate, FAIR Digital Objects (FDOs), and computational workflows, in order to examine research questions on how these can be implemented and integrated using Linked Data approaches – forming “FAIR Research Objects”. The background covers the evolution of the Semantic Web, Linked Data, and FAIR Digital Objects, which are evaluated against the FAIR principles and several frameworks, to consider these technologies as potential middleware for a global distributed object system that enable machine-actionable research outputs. This work introduces the community-developed method RO-Crate for packaging research artefacts with their contextual information, relationships and metadata – utilising Linked Data standards that are simplified and documented for pragmatic use by software developers. The tension between flexibility for implementations and rigidity of semantic constraints is explored, and demonstrated by profiles of RO-Crate across research domains such as bioinformatics, regulatory sciences, biodiversity and digital humanities. Computational workflows, for reproducible data analysis across execution platforms, are examined as potential FAIR Digital Objects, considering them both as shareable research outputs as well as a part of provenance of computational results, captured in a Workflow Run Crate. This thesis explores the emerging ecosystem of FAIR Digital Objects and how it can learn from the community development of RO-Crate to carefully adapt ’just enough’ of Linked Data technologies, balancing flexibility and predictability. The main findings of this thesis emphasise community-driven pragmatic solutions over strict semantic correctness, supporting advancement of the FAIR principles through practical and interoperable implementations of Web standards. </p>
  </span>
  
</div>
</li>
<li>

<div id="islakoglu2025acl">
  
    <span class="title">ChronoSense: Exploring Temporal Understanding in Large Language Models with Time Intervals of Events</span>
    <span class="author">
      
        
          
            
              
                Duygu Sezen Islakoglu,
              
            
          
        
      
        
          
            
              
                and Jan-Christoph Kalo
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics</em>
    
    
      2025
    
    </span>
  

  <span class="links">
  
  
    [<a href="http://arxiv.org/abs/2501.03040" target="_blank">arXiv</a>]
  
  
  
  
    [<a href="https://arxiv.org/abs/2501.03040" target="_blank">Link</a>]
  
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="DBLP:conf/semweb/2024hgais">
  
    <span class="title">Proceedings of the Special Session on Harmonising Generative AI
    and Semantic Web Technologies (HGAIS 2024) co-located with the 23rd
 International Semantic Web Conference (ISWC 2024), Baltimore, Maryland,
 November 13, 2024</span>
    <span class="author">
      
    </span>

    <span class="periodical">
    
    
      2025
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="https://ceur-ws.org/Vol-3953" target="_blank">Link</a>]
  
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="10.1145/3672608.3707743">
  
    <span class="title">Contrasting Global and Local Representations for Human Activity Recognition using Graph Neural Networks</span>
    <span class="author">
      
        
          
            
              
                Andrés Tello,
              
            
          
        
      
        
          
            
              
                and Victoria Degeler
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Proceedings of the 40th ACM/SIGAPP Symposium on Applied Computing</em>
    
    
      2025
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
  
    [<a href="https://doi.org/10.1145/3672608.3707743" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.1145/3672608.3707743" target="_blank">DOI:10.1145/3672608.3707743</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Human Activity Recognition has achieved notable improvements with the emergence of Deep Learning models for automated feature extraction. Those models allow to extract complex translational-invariant features and to exploit the temporal dependencies from sensors’ time series data. This work posits additional dependencies between sensors beyond the time dimension, such as physical proximity, which are equally important for the characterization of human activities. We leverage such spatial dependencies by modeling them as a graph. Using Graph Neural Networks (GNNs), we learn global and local representations of the intra- and intersensor dependencies. We empirically show that by maximizing the mutual information between the local and global representations, the performance of the recognition models can be significantly improved. Our results show a clear improvement over previous works based on CNNs, LSTMs, Attention-based and other more complex GNNs-based architectures. Our source code is available at: https://github.com/atello/GNNs4HAR</p>
  </span>
  
</div>
</li>
<li>

<div id="10986765">
  
    <span class="title">Rethinking Computing Systems in the Era of Climate Crisis: A Call for a Sustainable Computing Continuum</span>
    <span class="author">
      
        
          
            
              
                Ella Peltonen,
              
            
          
        
      
        
          
            
              
                Suzan Bayhan,
              
            
          
        
      
        
          
            
              
                David Bermbach,
              
            
          
        
      
        
          
            
              
                Sebastian Buschjager,
              
            
          
        
      
        
          
            
              
                Victoria Degeler,
              
            
          
        
      
        
          
            
              
                Aaron Yi Ding,
              
            
          
        
      
        
          
            
              
                Ozlem Durmaz Incel,
              
            
          
        
      
        
          
            
              
                Dewant Katare,
              
            
          
        
      
        
          
            
              
                Mikkel Baun Kjargaard,
              
            
          
        
      
        
          
            
              
                Sam Leroux,
              
            
          
        
      
        
          
            
              
                Toktam Mahmoodi,
              
            
          
        
      
        
          
            
              
                Zoltan Adam Mann,
              
            
          
        
      
        
          
            
              
                Nirvana Meratnia,
              
            
          
        
      
        
          
            
              
                Andy D. Pimentel,
              
            
          
        
      
        
          
            
              
                Jan S. Rellermeyer,
              
            
          
        
      
        
          
            
              
                Etienne Riviere,
              
            
          
        
      
        
          
            
              
                Dolly Sapra,
              
            
          
        
      
        
          
            
              
                Gurkan Solmaz,
              
            
          
        
      
        
          
            
              
                and Bram van der Waaij
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>IEEE Internet Computing</em>
    
    
      2025
    
    </span>
  

  <span class="links">
  
  
  
  
  
  
    [<a href="http://doi.org/10.1109/MIC.2025.3566642" target="_blank">DOI:10.1109/MIC.2025.3566642</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="10.1145/3703790.3703834">
  
    <span class="title">3K: Knowledge-Enriched Digital Twin Framework</span>
    <span class="author">
      
        
          
            
              
                Erkan Karabulut,
              
            
          
        
      
        
          
            
              
                Paul Groth,
              
            
          
        
      
        
          
            
              
                and Victoria Degeler
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Proceedings of the 14th International Conference on the Internet of Things</em>
    
    
      2025
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
  
    [<a href="https://doi.org/10.1145/3703790.3703834" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.1145/3703790.3703834" target="_blank">DOI:10.1145/3703790.3703834</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Digital Twins (DTs) are the digital equivalent of physical entities that facilitate, among others, monitoring and decision-making, thus helping extend the longevity of the twinned entity. DTs with automated decision-making capabilities require explainable inference mechanisms, especially for critical infrastructures such as water networks. Here we introduce 3K, a DT framework that aims for knowledge-enriched inference that is explainable and fast, by synthesizing knowledge representation (semantics) and knowledge discovery methods. 3K constructs a knowledge graph, which is becoming a mainstream way of metadata storage in DTs, and proposes a new method that can run on both sensor data and knowledge graphs to learn semantic association rules. The rules represent the expected working conditions of the DT and we argue that when combined with domain knowledge in the form of ontological axioms, semantic association rules can help perform downstream tasks in DTs, including extending the longevity of the twinned entities such as an Internet of Things (IoT) system. Furthermore, we demonstrate the 3K framework in a water distribution network use case and show how it can be used for downstream tasks.</p>
  </span>
  
</div>
</li>
<li>

<div id="DBLP:conf/edbt/ZhangGCS25">
  
    <span class="title">A Deep Dive Into Cross-Dataset Entity Matching with Large and Small
 Language Models</span>
    <span class="author">
      
        
          
            
              
                Zeyu Zhang,
              
            
          
        
      
        
          
            
              
                Paul Groth,
              
            
          
        
      
        
          
            
              
                Iacer Calixto,
              
            
          
        
      
        
          
            
              
                and Sebastian Schelter
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Proceedings 28th International Conference on Extending Database Technology,
                  EDBT 2025, Barcelona, Spain, March 25-28, 2025</em>
    
    
      2025
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="https://doi.org/10.48786/edbt.2025.75" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.48786/EDBT.2025.75" target="_blank">DOI:10.48786/EDBT.2025.75</a>]
  
  
  
  
  
    [<a href="https://github.com/Jantory/cross-dataset-em-study" target="_blank">Code</a>]
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="MOHAMMED2025102549">
  
    <span class="title">The effects of data quality on machine learning performance on tabular data</span>
    <span class="author">
      
        
          
            
              
                Sedir Mohammed,
              
            
          
        
      
        
          
            
              
                Lukas Budach,
              
            
          
        
      
        
          
            
              
                Moritz Feuerpfeil,
              
            
          
        
      
        
          
            
              
                Nina Ihde,
              
            
          
        
      
        
          
            
              
                Andrea Nathansen,
              
            
          
        
      
        
          
            
              
                Nele Noack,
              
            
          
        
      
        
          
            
              
                Hendrik Patzlaff,
              
            
          
        
      
        
          
            
              
                Felix Naumann,
              
            
          
        
      
        
          
            
              
                and Hazar Harmouch
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>Information Systems</em>
    
    
      2025
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
  
    [<a href="https://www.sciencedirect.com/science/article/pii/S0306437925000341" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/https://doi.org/10.1016/j.is.2025.102549" target="_blank">DOI:https://doi.org/10.1016/j.is.2025.102549</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Modern artificial intelligence (AI) applications require large quantities of training and test data. This need creates critical challenges not only concerning the availability of such data, but also regarding its quality. For example, incomplete, erroneous, or inappropriate training data can lead to unreliable models that produce ultimately poor decisions. Trustworthy AI applications require high-quality training and test data along many quality dimensions, such as accuracy, completeness, and consistency. We explore empirically the relationship between six data quality dimensions and the performance of 19 popular machine learning algorithms covering the tasks of classification, regression, and clustering, with the goal of explaining their performance in terms of data quality. Our experiments distinguish three scenarios based on the AI pipeline steps that were fed with polluted data: polluted training data, test data, or both. We conclude the paper with an extensive discussion of our observations.</p>
  </span>
  
</div>
</li>
<li>

<div id="DBLP:conf/edbt/MohammedNH25">
  
    <span class="title">Step-by-Step Data Cleaning Recommendations to Improve ML Prediction
 Accuracy</span>
    <span class="author">
      
        
          
            
              
                Sedir Mohammed,
              
            
          
        
      
        
          
            
              
                Felix Naumann,
              
            
          
        
      
        
          
            
              
                and Hazar Harmouch
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Proceedings 28th International Conference on Extending Database Technology,
                    EDBT 2025, Barcelona, Spain, March 25-28, 2025</em>
    
    
      2025
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="https://doi.org/10.48786/edbt.2025.43" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.48786/EDBT.2025.43" target="_blank">DOI:10.48786/EDBT.2025.43</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="10.1145/3689187.3709609">
  
    <span class="title">Data Systems Education: Curriculum Recommendations, Course Syllabi, and Industry Needs</span>
    <span class="author">
      
        
          
            
              
                Daphne Miedema,
              
            
          
        
      
        
          
            
              
                Toni Taipalus,
              
            
          
        
      
        
          
            
              
                Vangel V. Ajanovski,
              
            
          
        
      
        
          
            
              
                Abdussalam Alawini,
              
            
          
        
      
        
          
            
              
                Martin Goodfellow,
              
            
          
        
      
        
          
            
              
                Michael Liut,
              
            
          
        
      
        
          
            
              
                Svetlana Peltsverger,
              
            
          
        
      
        
          
            
              
                and Tiffany Young
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In 2024 Working Group Reports on Innovation and Technology in Computer Science Education</em>
    
    
      2025
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
  
    [<a href="https://doi.org/10.1145/3689187.3709609" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.1145/3689187.3709609" target="_blank">DOI:10.1145/3689187.3709609</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Data systems have been an important part of computing curricula for decades, and an integral part of data-focused industry roles such as software developers, data engineers, and data scientists. However, the field of data systems encompasses a large number of topics ranging from data manipulation and database distribution to creating data pipelines and data analytics solutions. Due to the slow nature of curriculum development, it remains unclear (i) which data systems topics are recommended across diverse higher education curriculum guidelines, (ii) which topics are taught in higher education data systems courses, and (iii) which data systems topics are actually valued in data-focused industry roles. In this study, we analyzed computing curriculum guidelines, course contents, and industry needs regarding data systems to uncover discrepancies between them. Our results show, for example, that topics such as data visualization, data warehousing, and semi-structured data models are valued in industry, yet seldom taught in courses. This work allows professionals to further align curriculum guidelines, higher education, and data systems industry to better prepare students for their working life by focusing on relevant skills in data systems education.</p>
  </span>
  
</div>
</li>
<li>

<div id="zhang2025anymatch">
  
    <span class="title">ANYMATCH – Efficient Zero-Shot Entity Matching with a Small Language Model</span>
    <span class="author">
      
        
          
            
              
                Zeyu Zhang,
              
            
          
        
      
        
          
            
              
                Paul Groth,
              
            
          
        
      
        
          
            
              
                Iacer Calixto,
              
            
          
        
      
        
          
            
              
                and Sebastian Schelter
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Workshop on Preparing Good Data for Generative AI: Challenges and Approaches at AAAI</em>
    
    
      2025
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="https://arxiv.org/pdf/2409.04073" target="_blank">Link</a>]
  
  
  
  
  
  
    [<a href="https://github.com/Jantory/anymatch" target="_blank">Code</a>]
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
</ol>

<h3 class="year">2024</h3>
<ol class="bibliography">
<li>

<div id="dazaphd">
  
    <span class="title">Exploiting Subgraphs and Attributes for Representation Learning on Knowledge Graphs</span>
    <span class="author">
      
        
          
            Daniel Fernando Daza Cruz
          
        
      
    </span>

    <span class="periodical">
    
    
      2024
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
  
  
    [<a href="http://doi.org/10.5463/thesis.823" target="_blank">DOI:10.5463/thesis.823</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Knowledge graphs (KGs) are data structures that explicitly represent entities and the relations between them over some domain. They can be used to store information about people and their relatives or birth locations, about organizations and the countries where they are located, or about chemical compounds and their interactions with proteins in the human body. In this thesis, we investigate the problem of representation learning on knowledge graphs, which consists of learning vector representations of entities and relations that capture the information contained in the graph. These learned representations are useful for capturing patterns that occur in the graph but are not explicitly stated in it. Several methods for representation learning on KGs are based on predicting a link between a pair of entities in the graph. While efficient, this approach forgoes useful learning signals from other sources that exhibit patterns, such as subgraphs involving multiple entities, and attributes of entities. Examples of attributes are textual descriptions of people, or molecular structures of chemical compounds. The goal of this thesis is to explore such learning signals beyond pairwise interactions of entities. Our findings provide evidence that subgraphs and attributes are powerful signals from which we can learn representations in KGs. Not only do they yield improved representations, but they also broaden the range of tasks in which they can be applied. We hope that this serves as a motivation for learning from further sources of information that are already available in KGs, but whose potential is yet to be discovered.</p>
  </span>
  
</div>
</li>
<li>

<div id="nevinphd">
  
    <span class="title">The Ramifications of Data Handling for Computational Models</span>
    <span class="author">
      
        
          
            James Graham Nevin
          
        
      
    </span>

    <span class="periodical">
    
    
      2024
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="https://hdl.handle.net/11245.1/d3da6b23-4198-40f6-bfc1-278477bdb0a5" target="_blank">Link</a>]
  
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="Nevin2024">
  
    <span class="title">Understanding the Impact of Entity Linking on the Topology of Entity Co-occurrence Networks for Social Media Analysis</span>
    <span class="author">
      
        
          
            
              
                James Nevin,
              
            
          
        
      
        
          
            
              
                Pengyu Zhang,
              
            
          
        
      
        
          
            
              
                Dimitar Dimitrov,
              
            
          
        
      
        
          
            
              
                Michael Lees,
              
            
          
        
      
        
          
            
              
                Paul Groth,
              
            
          
        
      
        
          
            
              
                and Stefan Dietze
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Knowledge Engineering and Knowledge Management (EKAW)</em>
    
    
      2024
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="https://rdcu.be/d1uKM" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.1007/978-3-031-77792-9_5" target="_blank">DOI:10.1007/978-3-031-77792-9_5</a>]
  
  
  
  
  
    [<a href="https://github.com/jim-g-n/Tweet-Linked-Entity-Co-occurrence/tree/main" target="_blank">Code</a>]
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="degeler2024llm_ontology_learning">
  
    <span class="title">Large Language Model for Ontology Learning in Drinking Water Distribution Network Domain</span>
    <span class="author">
      
        
          
            
              
                Y. Huang,
              
            
          
        
      
        
          
            
              
                E. Karabulut,
              
            
          
        
      
        
          
            
              
                and V. Degeler
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Proceedings of the 24th International Conference on Knowledge Engineering and Knowledge Management Posters, Demos, Workshops, and Tutorials (EKAW‑PDWT 2024)</em>
    
    
      2024
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="https://ceur-ws.org/Vol-3967/ELMKE_2024_paper_1.pdf" target="_blank">Link</a>]
  
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="allen_benchmark_2024">
  
    <span class="title">A benchmark for the detection of metalinguistic disagreements between LLMs and knowledge graphs</span>
    <span class="author">
      
        
          
            
              
                Bradley Allen,
              
            
          
        
      
        
          
            
              
                and Paul Groth
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Proceedings of the Special Session on Harmonising Generative AI and Semantic Web Technologies (HGAIS 2024)</em>
    
    
      2024
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="https://ceur-ws.org/Vol-3953/#356" target="_blank">Link</a>]
  
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="Liberatore2024">
  
    <span class="title">Influence Beyond Similarity: A Contrastive Learning Approach to Object Influence Retrieval</span>
    <span class="author">
      
        
          
            
              
                Teresa Liberatore,
              
            
          
        
      
        
          
            
              
                Paul Groth,
              
            
          
        
      
        
          
            
              
                Monika Kackovic,
              
            
          
        
      
        
          
            
              
                and Nachoem Wijnberg
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Knowledge Engineering and Knowledge Management (EKAW)</em>
    
    
      2024
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="https://rdcu.be/d1uLe" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.1007/978-3-031-77792-9_3" target="_blank">DOI:10.1007/978-3-031-77792-9_3</a>]
  
  
  
  
  
    [<a href="https://github.com/traopia/CLOIR" target="_blank">Code</a>]
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="Zhang2024">
  
    <span class="title">TIGER: Temporally Improved Graph Entity Linker</span>
    <span class="author">
      
        
          
            
              
                Pengyu Zhang,
              
            
          
        
      
        
          
            
              
                Congfeng Cao,
              
            
          
        
      
        
          
            
              
                and Paul Groth
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In 27th European Conference on Artificial Intelligence (ECAI 24)</em>
    
    
      2024
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="http://dx.doi.org/10.3233/FAIA240933" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.3233/faia240933" target="_blank">DOI:10.3233/faia240933</a>]
  
  
  
  
  
    [<a href="https://github.com/pengyu-zhang/TIGER-Temporally-Improved-Graph-Entity-Linker" target="_blank">Code</a>]
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="degeler2024">
  
    <span class="title">DiTEC: Digital Twin for Evolutionary Changes in Water Distribution Networks</span>
    <span class="author">
      
        
          
            
              
                Victoria Degeler,
              
            
          
        
      
        
          
            
              
                Mostafa Hadadian,
              
            
          
        
      
        
          
            
              
                Erkan Karabulut,
              
            
          
        
      
        
          
            
              
                Alexander Lazovik,
              
            
          
        
      
        
          
            
              
                Hester Loo,
              
            
          
        
      
        
          
            
              
                Andrés Tello,
              
            
          
        
      
        
          
            
              
                and Huy Truong
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Leveraging Applications of Formal Methods, Verification and Validation. Application Areas</em>
    
    
      2024
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
  
    [<a href="https://link.springer.com/chapter/10.1007/978-3-031-75390-9_5" target="_blank">Link</a>]
  
  
  
  
  
  
    [<a href="https://github.com/DiTEC-project/" target="_blank">Code</a>]
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Conventional digital twins (DT) for critical infrastructures are widely used to model and simulate the system’s state. But fundamental environment changes bring challenges for DT adaptation to new conditions, leading to a progressively decreasing correspondence of the DT to its physical counterpart. This paper introduces the DiTEC system, a Digital Twin for Evolutionary Changes in Water Distribution Networks (WDN). This framework combines novel techniques, including semantic rule learning, graph neural network-based state estimation, and adaptive model selection, to ensure that changes are adequately detected, processed and the DT is updated to the new state. The DiTEC system is tested on the Dutch Oosterbeek region WDN, with results showing the superiority of the approach compared to traditional methods.</p>
  </span>
  
</div>
</li>
<li>

<div id="10.1145/3627673.3679702">
  
    <span class="title">CYCLE: Cross-Year Contrastive Learning in Entity-Linking</span>
    <span class="author">
      
        
          
            
              
                Pengyu Zhang,
              
            
          
        
      
        
          
            
              
                Congfeng Cao,
              
            
          
        
      
        
          
            
              
                Klim Zaporojets,
              
            
          
        
      
        
          
            
              
                and Paul Groth
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Proceedings of the 33rd ACM International Conference on Information and Knowledge Management (CIKM 24)</em>
    
    
      2024
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
  
    [<a href="https://doi.org/10.1145/3627673.3679702" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.1145/3627673.3679702" target="_blank">DOI:10.1145/3627673.3679702</a>]
  
  
  
  
  
    [<a href="https://github.com/pengyu-zhang/CYCLE-Cross-Year-Contrastive-Learning-in-Entity-Linking" target="_blank">Code</a>]
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Knowledge graphs constantly evolve with new entities emerging, existing definitions being revised, and entity relationships changing. These changes lead to temporal degradation in entity linking models, characterized as a decline in model performance over time. To address this issue, we propose leveraging graph relationships to aggregate information from neighboring entities across different time periods. This approach enhances the ability to distinguish similar entities over time, thereby minimizing the impact of temporal degradation. We introduce CYCLE: Cross-Year Contrastive Learning for Entity-Linking. This model employs a novel graph contrastive learning method to tackle temporal performance degradation in entity linking tasks. Our contrastive learning method treats newly added graph relationships as positive samples and newly removed ones as negative samples. This approach helps our model effectively prevent temporal degradation, achieving a 13.90% performance improvement over the state-of-the-art from 2023 when the time gap is one year, and a 17.79% improvement as the gap expands to three years. Further analysis shows that CYCLE is particularly robust for low-degree entities, which are less resistant to temporal degradation due to their sparse connectivity, making them particularly suitable for our method. The code and data are made available at https://github.com/pengyu-zhang/CYCLE-Cross-Year-Contrastive-Learning-in-Entity-Linking</p>
  </span>
  
</div>
</li>
<li>

<div id="Polat2024">
  
    <span class="title">Testing prompt engineering methods for knowledge extraction from text</span>
    <span class="author">
      
        
          
            
              
                Fina Polat,
              
            
          
        
      
        
          
            
              
                Ilaria Tiddi,
              
            
          
        
      
        
          
            
              
                and Paul Groth
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>Semantic Web</em>
    
    
      2024
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="http://dx.doi.org/10.3233/SW-243719" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.3233/sw-243719" target="_blank">DOI:10.3233/sw-243719</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="xu2024sparsity">
  
    <span class="title">A Sparsity Principle for Partially Observable Causal Representation Learning</span>
    <span class="author">
      
        
          
            
              
                Danru Xu,
              
            
          
        
      
        
          
            
              
                Dingling Yao,
              
            
          
        
      
        
          
            
              
                Sébastien Lachapelle,
              
            
          
        
      
        
          
            
              
                Perouz Taslakian,
              
            
          
        
      
        
          
            
              
                Julius Kügelgen,
              
            
          
        
      
        
          
            
              
                Francesco Locatello,
              
            
          
        
      
        
          
            
              
                and Sara Magliacane
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>International Conference on Machine Learning (ICML)</em>
    
    
      2024
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="https://arxiv.org/abs/2403.08335" target="_blank">Link</a>]
  
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="Li2024">
  
    <span class="title">How different is different? Systematically identifying distribution shifts and their impacts in NER datasets</span>
    <span class="author">
      
        
          
            
              
                Xue Li,
              
            
          
        
      
        
          
            
              
                and Paul Groth
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>Language Resources and Evaluation</em>
    
    
      2024
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="http://dx.doi.org/10.1007/s10579-024-09754-8" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.1007/s10579-024-09754-8" target="_blank">DOI:10.1007/s10579-024-09754-8</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="53679ad4091244cb8a4c62a4e6fcb95e">
  
    <span class="title">Towards Federated LLM-Powered CEP Rule Generation and Refinement</span>
    <span class="author">
      
        
          
            
              
                Majid Lotfian Delouee,
              
            
          
        
      
        
          
            
              
                Daria G. Pernes,
              
            
          
        
      
        
          
            
              
                Victoria Degeler,
              
            
          
        
      
        
          
            
              
                and Boris Koldehofe
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In The 18th ACM International Conference on Distributed and Event-Based Systems (DEBS’24)</em>
    
    
      2024
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
  
    [<a href="https://2024.debs.org/" target="_blank">Link</a>]
  
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>In traditional event processing systems, patterns representing situations of interest are typically defined by domain experts or learned from historical data. These approaches often make rule generation reactive, time-consuming, and susceptible to human error. In this paper, we propose and investigate the integration of large language models (LLMs) to automate and accelerate query translation and rule generation in event processing systems. Furthermore, we introduce a federated learning schema to refine the initially generated rules by examining them over distributed event streams, ensuring greater accuracy and adaptability.Preliminary results demonstrate the potential of LLMs as a key component in proactively expediting the autonomous rule-generation process. Moreover, our findings suggest that employing customized prompt engineering techniques can further enhance the quality of the generated rules.</p>
  </span>
  
</div>
</li>
<li>

<div id="allen2024shroomindelab">
  
    <span class="title">SHROOM-INDElab at SemEval-2024 Task 6: Zero- and Few-Shot LLM-Based Classification for Hallucination Detection</span>
    <span class="author">
      
        
          
            
              
                Bradley P. Allen,
              
            
          
        
      
        
          
            
              
                Fina Polat,
              
            
          
        
      
        
          
            
              
                and Paul Groth
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Proceedings of the 18th International Workshop on Semantic Evaluation (SemEval-2024)</em>
    
    
      2024
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="https://arxiv.org/abs/2404.03732" target="_blank">Link</a>]
  
  
  
  
  
  
    [<a href="https://github.com/bradleypallen/shroom" target="_blank">Code</a>]
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="10.1145/3650203.3663327">
  
    <span class="title">Towards Interactively Improving ML Data Preparation Code via "Shadow Pipelines"</span>
    <span class="author">
      
        
          
            
              
                Stefan Grafberger,
              
            
          
        
      
        
          
            
              
                Paul Groth,
              
            
          
        
      
        
          
            
              
                and Sebastian Schelter
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Proceedings of the Eighth Workshop on Data Management for End-to-End Machine Learning</em>
    
    
      2024
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
  
    [<a href="https://doi.org/10.1145/3650203.3663327" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.1145/3650203.3663327" target="_blank">DOI:10.1145/3650203.3663327</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Data scientists develop ML pipelines in an iterative manner: they repeatedly screen a pipeline for potential issues, debug it, and then revise and improve its code according to their findings. However, this manual process is tedious and error-prone. Therefore, we propose to support data scientists during this development cycle with automatically derived interactive suggestions for pipeline improvements. We discuss our vision to generate these suggestions with so-called shadow pipelines, hidden variants of the original pipeline that modify it to auto-detect potential issues, try out modifications for improvements, and suggest and explain these modifications to the user. We envision to apply incremental view maintenance-based optimisations to ensure low-latency computation and maintenance of the shadow pipelines. We conduct preliminary experiments to showcase the feasibility of our envisioned approach and the potential benefits of our proposed optimisations.</p>
  </span>
  
</div>
</li>
<li>

<div id="10.1145/3650203.3663334">
  
    <span class="title">Towards Efficient Data Wrangling with LLMs using Code Generation</span>
    <span class="author">
      
        
          
            
              
                Xue Li,
              
            
          
        
      
        
          
            
              
                and Till Döhmen
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Proceedings of the Eighth Workshop on Data Management for End-to-End Machine Learning</em>
    
    
      2024
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
  
    [<a href="https://doi.org/10.1145/3650203.3663334" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.1145/3650203.3663334" target="_blank">DOI:10.1145/3650203.3663334</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>While LLM-based data wrangling approaches that process each row of data have shown promising benchmark results, computational costs still limit their suitability for real-world use cases on large datasets. We revisit code generation using LLMs for various data wrangling tasks, which show promising results particularly for data transformation tasks (up to 37.2 points improvement on F1 score) at much lower computational costs. We furthermore identify shortcomings of code generation methods especially for semantically challenging tasks, and consequently propose an approach that combines program generation with a routing mechanism using LLMs.</p>
  </span>
  
</div>
</li>
<li>

<div id="buchner-etal-2024-prompt">
  
    <span class="title">Prompt Tuned Embedding Classification for Industry Sector Allocation</span>
    <span class="author">
      
        
          
            
              
                Valentin Buchner,
              
            
          
        
      
        
          
            
              
                Lele Cao,
              
            
          
        
      
        
          
            
              
                Jan-Christoph Kalo,
              
            
          
        
      
        
          
            
              
                and Vilhelm Von Ehrenheim
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 6: Industry Track)</em>
    
    
      2024
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
  
    [<a href="https://aclanthology.org/2024.naacl-industry.10/" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.18653/v1/2024.naacl-industry.10" target="_blank">DOI:10.18653/v1/2024.naacl-industry.10</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>We introduce Prompt Tuned Embedding Classification (PTEC) for classifying companies within an investment firm‘s proprietary industry taxonomy, supporting their thematic investment strategy. PTEC assigns companies to the sectors they primarily operate in, conceptualizing this process as a multi-label text classification task. Prompt Tuning, usually deployed as a text-to-text (T2T) classification approach, ensures low computational cost while maintaining high task performance. However, T2T classification has limitations on multi-label tasks due to the generation of non-existing labels, permutation invariance of the label sequence, and a lack of confidence scores. PTEC addresses these limitations by utilizing a classification head in place of the Large Language Models (LLMs) language head. PTEC surpasses both baselines and human performance while lowering computational demands. This indicates the continuing need to adapt state-of-the-art methods to domain-specific tasks, even in the era of LLMs with strong generalization abilities.</p>
  </span>
  
</div>
</li>
<li>

<div id="kruit-etal-2024-retrieval-based">
  
    <span class="title">Retrieval-based Question Answering with Passage Expansion Using a Knowledge Graph</span>
    <span class="author">
      
        
          
            
              
                Benno Kruit,
              
            
          
        
      
        
          
            
              
                Yiming Xu,
              
            
          
        
      
        
          
            
              
                and Jan-Christoph Kalo
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)</em>
    
    
      2024
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
  
    [<a href="https://aclanthology.org/2024.lrec-main.1225" target="_blank">Link</a>]
  
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Recent advancements in dense neural retrievers and language models have led to large improvements in state-of-the-art approaches to open-domain Question Answering (QA) based on retriever-reader architectures. However, issues stemming from data quality and imbalances in the use of dense embeddings have hindered performance, particularly for less common entities and facts. To tackle these problems, this study explores a multi-modal passage retrieval model’s potential to bolster QA system performance. This study poses three key questions: (1) Can a distantly supervised question-relation extraction model enhance retrieval using a knowledge graph (KG), compensating for dense neural retrievers’ shortcomings with rare entities? (2) How does this multi-modal approach compare to existing QA systems based on textual features? (3) Can this QA system alleviate poor performance on less common entities on common benchmarks? We devise a multi-modal retriever combining entity features and textual data, leading to improved retrieval precision in some situations, particularly for less common entities. Experiments across different datasets confirm enhanced performance for entity-centric questions, but challenges remain in handling complex generalized questions.</p>
  </span>
  
</div>
</li>
<li>

<div id="95c49d54c4694c3daf9d112441d37d93">
  
    <span class="title">Large-Scale Multipurpose Benchmark Datasets For Assessing Data-Driven Deep Learning Approaches For Water Distribution Networks</span>
    <span class="author">
      
        
          
            
              
                Andrés Tello,
              
            
          
        
      
        
          
            
              
                Huy Truong,
              
            
          
        
      
        
          
            
              
                Alexander Lazovik,
              
            
          
        
      
        
          
            
              
                and Victoria Degeler
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Engineering Proceedings</em>
    
    
      2024
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
  
    [<a href="https://arxiv.org/abs/2404.15386" target="_blank">Link</a>]
  
  
  
  
  
  
  
    [<a href="https://doi.org/10.5281/zenodo.11353195" target="_blank">Data</a>]
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Currently, the number of common benchmark datasets that researchers can use straight away for assessing data-driven deep learning approaches is very limited. Most studies provide data as configuration files. It is still up to each practitioner to follow a particular data generation method and run computationally intensive simulations to obtain usable data for model training and evaluation. In this work, we provide a collection of datasets that includes several small and medium size publicly available Water Distribution Networks (WDNs), including Anytown, Modena, Balerma, C-Town, D-Town, L-Town, Ky1, Ky6, Ky8, Ky10, and Ky13. In total 1,394,400 hours of WDNs data operating under normal conditions is made available to the community. </p>
  </span>
  
</div>
</li>
<li>

<div id="allen2024evaluating">
  
    <span class="title">Evaluating Class Membership Relations in Knowledge Graphs using Large Language Models</span>
    <span class="author">
      
        
          
            
              
                Bradley P. Allen,
              
            
          
        
      
        
          
            
              
                and Paul T. Groth
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Proceedings of European Semantic Web Conference Special Track on Large Language Models for Knowledge Engineering</em>
    
    
      2024
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="https://arxiv.org/abs/2404.17000" target="_blank">Link</a>]
  
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="10555056">
  
    <span class="title">Directions Towards Efficient and Automated Data Wrangling with Large Language Models</span>
    <span class="author">
      
        
          
            
              
                Zeyu Zhang,
              
            
          
        
      
        
          
            
              
                Paul Groth,
              
            
          
        
      
        
          
            
              
                Iacer Calixto,
              
            
          
        
      
        
          
            
              
                and Sebastian Schelter
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In 2024 IEEE 40th International Conference on Data Engineering Workshops (ICDEW)</em>
    
    
      2024
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="https://www.wis.ewi.tudelft.nl/assets/files/dbml2024/DBML24_paper_1.pdf" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.1109/ICDEW61823.2024.00044" target="_blank">DOI:10.1109/ICDEW61823.2024.00044</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="10.1145/3654975">
  
    <span class="title">SchemaPile: A Large Collection of Relational Database Schemas</span>
    <span class="author">
      
        
          
            
              
                Till Döhmen,
              
            
          
        
      
        
          
            
              
                Radu Geacu,
              
            
          
        
      
        
          
            
              
                Madelon Hulsebos,
              
            
          
        
      
        
          
            
              
                and Sebastian Schelter
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>Proc. ACM Manag. Data</em>
    
    
      2024
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
  
    [<a href="https://doi.org/10.1145/3654975" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.1145/3654975" target="_blank">DOI:10.1145/3654975</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Access to fine-grained schema information is crucial for understanding how relational databases are designed and used in practice, and for building systems that help users interact with them. Furthermore, such information is required as training data to leverage the potential of large language models (LLMs) for improving data preparation, data integration and natural language querying. Existing single-table corpora such as GitTables provide insights into how tables are structured in-the-wild, but lack detailed schema information about how tables relate to each other, as well as metadata like data types or integrity constraints. On the other hand, existing multi-table (or database schema) datasets are rather small and attribute-poor, leaving it unclear to what extent they actually represent typical real-world database schemas.In order to address these challenges, we present SchemaPile, a corpus of 221,171 database schemas, extracted from SQL files on GitHub. It contains 1.7 million tables with 10 million column definitions, 700 thousand foreign key relationships, seven million integrity constraints, and data content for more than 340 thousand tables. We conduct an in-depth analysis on the millions of schema metadata properties in our corpus, as well as its highly diverse language and topic distribution. In addition, we showcase the potential of corpus to improve a variety of data management applications, e.g., fine-tuning LLMs for schema-only foreign key detection, improving CSV header detection and evaluating multi-dialect SQL parsers. We publish the code and data for recreating SchemaPile and a permissively licensed subset SchemaPile-Perm.</p>
  </span>
  
</div>
</li>
<li>

<div id="karla2024data">
  
    <span class="title">Data Debugging with Shapley Importance over Machine Learning Pipelines</span>
    <span class="author">
      
        
          
            
              
                Bojan Karlaš,
              
            
          
        
      
        
          
            
              
                David Dao,
              
            
          
        
      
        
          
            
              
                Matteo Interlandi,
              
            
          
        
      
        
          
            
              
                Sebastian Schelter,
              
            
          
        
      
        
          
            
              
                Wentao Wu,
              
            
          
        
      
        
          
            
              
                and Ce Zhang
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In The Twelfth International Conference on Learning Representations</em>
    
    
      2024
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="https://openreview.net/forum?id=qxGXjWxabq" target="_blank">Link</a>]
  
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="yao2024multiview">
  
    <span class="title">Multi-View Causal Representation Learning with Partial Observability</span>
    <span class="author">
      
        
          
            
              
                Dingling Yao,
              
            
          
        
      
        
          
            
              
                Danru Xu,
              
            
          
        
      
        
          
            
              
                Sébastien Lachapelle,
              
            
          
        
      
        
          
            
              
                Sara Magliacane,
              
            
          
        
      
        
          
            
              
                Perouz Taslakian,
              
            
          
        
      
        
          
            
              
                Georg Martius,
              
            
          
        
      
        
          
            
              
                Julius Kügelgen,
              
            
          
        
      
        
          
            
              
                and Francesco Locatello
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In The Twelfth International Conference on Learning Representations</em>
    
    
      2024
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="https://openreview.net/forum?id=OGtnhKQJms" target="_blank">Link</a>]
  
  
  
  
  
  
  
  
    [<a href="https://openreview.net/group?id=ICLR.cc/2024/Conference#tab-accept-spotlight%20" target="_blank"> <img class="emoji" title=":tada:" alt=":tada:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f389.png" height="20" width="20"> Spotlight Presentation </a>]
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="10.7717/peerj-cs.1781">
  
    <span class="title">Evaluating FAIR Digital Object and Linked Data as distributed object systems</span>
    <span class="author">
      
        
          
            
              
                Stian Soiland-Reyes,
              
            
          
        
      
        
          
            
              
                Carole Goble,
              
            
          
        
      
        
          
            
              
                and Paul Groth
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>PeerJ Computer Science</em>
    
    
      2024
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
  
    [<a href="https://doi.org/10.7717/peerj-cs.1781" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.7717/peerj-cs.1781" target="_blank">DOI:10.7717/peerj-cs.1781</a>]
  
  
  
  
  
  
    [<a href="https://zenodo.org/doi/10.5281/zenodo.8075229" target="_blank">Data</a>]
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>
FAIR Digital Object (FDO) is an emerging concept that is highlighted by European Open Science Cloud (EOSC) as a potential candidate for building an ecosystem of machine-actionable research outputs. In this work we systematically evaluate FDO and its implementations as a global distributed object system, by using five different conceptual frameworks that cover interoperability, middleware, FAIR principles, EOSC requirements and FDO guidelines themself. We compare the FDO approach with established Linked Data practices and the existing Web architecture, and provide a brief history of the Semantic Web while discussing why these technologies may have been difficult to adopt for FDO purposes. We conclude with recommendations for both Linked Data and FDO communities to further their adaptation and alignment.
</p>
  </span>
  
</div>
</li>
<li>

<div id="Karabulut2024">
  
    <span class="title">Ontologies in digital twins: A systematic literature review</span>
    <span class="author">
      
        
          
            
              
                Erkan Karabulut,
              
            
          
        
      
        
          
            
              
                Salvatore F. Pileggi,
              
            
          
        
      
        
          
            
              
                Paul Groth,
              
            
          
        
      
        
          
            
              
                and Victoria Degeler
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>Future Generation Computer Systems</em>
    
    
      2024
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="http://dx.doi.org/10.1016/j.future.2023.12.013" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.1016/j.future.2023.12.013" target="_blank">DOI:10.1016/j.future.2023.12.013</a>]
  
  
  
  
  
  
    [<a href="https://doi.org/10.5281/zenodo.8172341" target="_blank">Data</a>]
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="c0a379de00c44101be1cb02eeeb33afe">
  
    <span class="title">Driving Towards Efficiency: Adaptive Resource-aware Clustered Federated Learning in Vehicular Networks</span>
    <span class="author">
      
        
          
            
              
                Ahmad Khalil,
              
            
          
        
      
        
          
            
              
                Majid Lotfian Delouee,
              
            
          
        
      
        
          
            
              
                Victoria Degeler,
              
            
          
        
      
        
          
            
              
                Tobias Meuser,
              
            
          
        
      
        
          
            
              
                Antonio Fernandez Anta,
              
            
          
        
      
        
          
            
              
                and Boris Koldehofe
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In The 22nd Mediterranean Communication and Computer Networking Conference (MedComNet’24)</em>
    
    
      2024
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
  
    [<a href="https://pure.rug.nl/ws/portalfiles/portal/979334276/authors_version_Driving_Towards_Efficiency_MedComNet_2024.pd" target="_blank">Link</a>]
  
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Guaranteeing precise perception for fully autonomous driving in diverse driving conditions requires continuous improvement and training. In vehicular networks, federated learning (FL) facilitates this by enabling model training without sharing raw sensory data. As an extension, clustered FL reduces communication overhead and aligns well with the dynamic nature of these networks. However, current literature on this topic does not consider critical dimensions of FL, including (1) the correlation between perception performance and the networking overhead, (2) the limited vehicle storage, (3) the need for training with freshly captured data, and (4) the impact of non-IID data and varying traffic densities. To fill these research gaps, we introduce AR-CFL, an Adaptive Resource-aware Clustered Federated Learning framework. AR-CFL utilizes clustered FL to collectively model the environment of connected vehicles, integrating models from all vehicles and ensuring universal accessibility to the refined model. AR-CFL dynamically enhances system efficiency by adaptively adjusting the number of clusters and specific in-cluster participant selection strategies. Using AR-CFL, we systematically study the scenario of online car detection model training on non-IID data across varied conditions. The evaluation results highlight the robust detection performance exhibited by the trained model employing the clustered FL approach, despite the constraints posed by limited vehicle storage capacity. Furthermore, our investigation unveils superior training performance with clustered FL in comparison to specific classical FL scenarios, increasing the training efficiency in terms of participating nodes by up to 25% and reducing cellular communication by 33%.</p>
  </span>
  
</div>
</li>
<li>

<div id="Carriero2024">
  
    <span class="title">Empirical ontology design patterns and shapes from Wikidata</span>
    <span class="author">
      
        
          
            
              
                Valentina Anita Carriero,
              
            
          
        
      
        
          
            
              
                Paul Groth,
              
            
          
        
      
        
          
            
              
                and Valentina Presutti
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>Semantic Web</em>
    
    
      2024
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="http://dx.doi.org/10.3233/SW-243613" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.3233/sw-243613" target="_blank">DOI:10.3233/sw-243613</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="Redyuk2024">
  
    <span class="title">Assisted design of data science pipelines</span>
    <span class="author">
      
        
          
            
              
                Sergey Redyuk,
              
            
          
        
      
        
          
            
              
                Zoi Kaoudi,
              
            
          
        
      
        
          
            
              
                Sebastian Schelter,
              
            
          
        
      
        
          
            
              
                and Volker Markl
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>The VLDB Journal</em>
    
    
      2024
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="http://dx.doi.org/10.1007/s00778-024-00835-2" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.1007/s00778-024-00835-2" target="_blank">DOI:10.1007/s00778-024-00835-2</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="hulsebos_table_2024">
  
    <span class="title">Table Representation Learning</span>
    <span class="author">
      
        
          
            Madelon Hulsebos
          
        
      
    </span>

    <span class="periodical">
    
    
      2024
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="https://dare.uva.nl/search?identifier=74d21daa-16a3-488f-a618-3f49300137e9" target="_blank">Link</a>]
  
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="10.1145/3643035">
  
    <span class="title">Domain Generalization in Time Series Forecasting</span>
    <span class="author">
      
        
          
            
              
                Songgaojun Deng,
              
            
          
        
      
        
          
            
              
                Olivier Sprangers,
              
            
          
        
      
        
          
            
              
                Ming Li,
              
            
          
        
      
        
          
            
              
                Sebastian Schelter,
              
            
          
        
      
        
          
            
              
                and Maarten Rijke
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>ACM Trans. Knowl. Discov. Data</em>
    
    
      2024
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
  
    [<a href="https://doi.org/10.1145/3643035" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.1145/3643035" target="_blank">DOI:10.1145/3643035</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Domain generalization aims to design models that can effectively generalize to unseen target domains by learning from observed source domains. Domain generalization poses a significant challenge for time series data, due to varying data distributions and temporal dependencies. Existing approaches to domain generalization are not designed for time series data, which often results in suboptimal or unstable performance when confronted with diverse temporal patterns and complex data characteristics. We propose a novel approach to tackle the problem of domain generalization in time series forecasting. We focus on a scenario where time series domains share certain common attributes and exhibit no abrupt distribution shifts. Our method revolves around the incorporation of a key regularization term into an existing time series forecasting model: domain discrepancy regularization. In this way, we aim to enforce consistent performance across different domains that exhibit distinct patterns. We calibrate the regularization term by investigating the performance within individual domains and propose the domain discrepancy regularization with domain difficulty awareness. We demonstrate the effectiveness of our method on multiple datasets, including synthetic and real-world time series datasets from diverse domains such as retail, transportation, and finance. Our method is compared against traditional methods, deep learning models, and domain generalization approaches to provide comprehensive insights into its performance. In these experiments, our method showcases superior performance, surpassing both the base model and competing domain generalization models across all datasets. Furthermore, our method is highly general and can be applied to various time series models.</p>
  </span>
  
</div>
</li>
<li>

<div id="vanEtten2024">
  
    <span class="title">Large-Scale Forecasting of Electric Vehicle Charging Demand Using Global Time Series Modeling</span>
    <span class="author">
      
        
          
            
              
                Tijmen Etten,
              
            
          
        
      
        
          
            
              
                Victoria Degeler,
              
            
          
        
      
        
          
            
              
                and Ding Luo
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Proceedings of the 10th International Conference on Vehicle Technology and Intelligent Transport Systems</em>
    
    
      2024
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="http://dx.doi.org/10.5220/0012555400003702" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.5220/0012555400003702" target="_blank">DOI:10.5220/0012555400003702</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="Groth2024">
  
    <span class="title">Editorial for the Special Issue on Knowledge Engineering</span>
    <span class="author">
      
        
          
            
              
                Paul Groth,
              
            
          
        
      
        
          
            
              
                Eva Blomqvist,
              
            
          
        
      
        
          
            
              
                and Juan F. Sequeda
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>Journal of Web Semantics</em>
    
    
      2024
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="http://dx.doi.org/10.1016/j.websem.2024.100840" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.1016/j.websem.2024.100840" target="_blank">DOI:10.1016/j.websem.2024.100840</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="10433778">
  
    <span class="title">Automated Data Cleaning Can Hurt Fairness in Machine Learning-based Decision Making</span>
    <span class="author">
      
        
          
            
              
                Shubha Guha,
              
            
          
        
      
        
          
            
              
                Falaah Arif Khan,
              
            
          
        
      
        
          
            
              
                Julia Stoyanovich,
              
            
          
        
      
        
          
            
              
                and Sebastian Schelter
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>IEEE Transactions on Knowledge and Data Engineering</em>
    
    
      2024
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="https://ieeexplore.ieee.org/document/10433778" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.1109/TKDE.2024.3365524" target="_blank">DOI:10.1109/TKDE.2024.3365524</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="allen_et_al:TGDK.2.1.5">
  
    <span class="title">Standardizing Knowledge Engineering Practices with a Reference Architecture</span>
    <span class="author">
      
        
          
            
              
                Bradley P. Allen,
              
            
          
        
      
        
          
            
              
                and Filip Ilievski
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>Transactions on Graph Data and Knowledge</em>
    
    
      2024
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="https://drops.dagstuhl.de/entities/document/10.4230/TGDK.2.1.5" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.4230/TGDK.2.1.5" target="_blank">DOI:10.4230/TGDK.2.1.5</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="martorana2024zero">
  
    <span class="title">Zero-Shot Topic Classification of Column Headers: Leveraging LLMs for Metadata Enrichment</span>
    <span class="author">
      
        
          
            
              
                Margherita Martorana,
              
            
          
        
      
        
          
            
              
                Tobias Kuhn,
              
            
          
        
      
        
          
            
              
                Lise Stork,
              
            
          
        
      
        
          
            
              
                and Jacco Ossenbruggen
              
            
          
        
      
    </span>

    <span class="periodical">
    
    
      2024
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="https://ebooks.iospress.nl/doi/10.3233/SSW240006" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.3233/SSW240006" target="_blank">DOI:10.3233/SSW240006</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="grafberger2024red">
  
    <span class="title">Red Onions, Soft Cheese and Data: From Food Safety to Data Traceability for Responsible AI</span>
    <span class="author">
      
        
          
            
              
                Stefan Grafberger,
              
            
          
        
      
        
          
            
              
                Zeyu Zhang,
              
            
          
        
      
        
          
            
              
                Sebastian Schelter,
              
            
          
        
      
        
          
            
              
                and Ce Zhang
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>IEEE Data Engineering Bulletin</em>
    
    
      2024
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="http://sites.computer.org/debull/A24mar/p63.pdf" target="_blank">Link</a>]
  
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="10503465">
  
    <span class="title">Too Good To Be True: accuracy overestimation in (re)current practices for Human Activity Recognition</span>
    <span class="author">
      
        
          
            
              
                Andrés Tello,
              
            
          
        
      
        
          
            
              
                Victoria Degeler,
              
            
          
        
      
        
          
            
              
                and Alexander Lazovik
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In 2024 IEEE International Conference on Pervasive Computing and Communications Workshops and other Affiliated Events (PerCom Workshops)</em>
    
    
      2024
    
    </span>
  

  <span class="links">
  
  
  
  
  
  
    [<a href="http://doi.org/10.1109/PerComWorkshops59983.2024.10503465" target="_blank">DOI:10.1109/PerComWorkshops59983.2024.10503465</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="truong2023graph">
  
    <span class="title">Graph Neural Networks for Pressure Estimation in Water Distribution Systems</span>
    <span class="author">
      
        
          
            
              
                Huy Truong,
              
            
          
        
      
        
          
            
              
                Andrés Tello,
              
            
          
        
      
        
          
            
              
                Alexander Lazovik,
              
            
          
        
      
        
          
            
              
                and Victoria Degeler
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>Water Resources Research</em>
    
    
      2024
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="https://arxiv.org/abs/2311.10579" target="_blank">Link</a>]
  
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
</ol>

<h3 class="year">2023</h3>
<ol class="bibliography">
<li>

<div id="Daza2023">
  
    <span class="title">BioBLP: a modular framework for learning on multimodal biomedical knowledge graphs</span>
    <span class="author">
      
        
          
            
              
                Daniel Daza,
              
            
          
        
      
        
          
            
              
                Dimitrios Alivanistos,
              
            
          
        
      
        
          
            
              
                Payal Mitra,
              
            
          
        
      
        
          
            
              
                Thom Pijnenburg,
              
            
          
        
      
        
          
            
              
                Michael Cochez,
              
            
          
        
      
        
          
            
              
                and Paul Groth
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>Journal of Biomedical Semantics</em>
    
    
      2023
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="http://dx.doi.org/10.1186/s13326-023-00301-y" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.1186/s13326-023-00301-y" target="_blank">DOI:10.1186/s13326-023-00301-y</a>]
  
  
  
  
  
    [<a href="https://github.com/elsevier-AI-Lab/BioBLP" target="_blank">Code</a>]
  
  
    [<a href="https://doi.org/10.5281/zenodo.8005711" target="_blank">Data</a>]
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="9ccf387264be4b898ad0beff3b46b233">
  
    <span class="title">APP-CEP: Adaptive Pattern-level Privacy Protection in Complex Event Processing Systems</span>
    <span class="author">
      
        
          
            
              
                Majid Lotfian Delouee,
              
            
          
        
      
        
          
            
              
                Victoria Degeler,
              
            
          
        
      
        
          
            
              
                Peter Amthor,
              
            
          
        
      
        
          
            
              
                and Boris Koldehofe
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In 10th International Conference on Information Systems Security and Privacy (ICISSP’24)</em>
    
    
      2023
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
  
    [<a href="http://icissp.scitevents.org" target="_blank">Link</a>]
  
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Although privacy-preserving mechanisms endeavor to safeguard sensitive information at the attribute level, detected event patterns can still disclose privacy-sensitive knowledge in distributed complex event processing systems (DCEP). Events might not be inherently sensitive, but their aggregation into a pattern could still breach privacy. In this paper, we study in the context of APP-CEP the problem of integrating pattern-level privacy in event-based systems by selective assignment of obfuscation techniques to conceal private information. Compared to state-of-the-art techniques, we seek to enforce privacy independent of the actual events in streams. To support this, we acquire queries and privacy requirements using CEP-like patterns. The protection of privacy is accomplished through generating pattern dependency graphs, leading to dynamically appointing those techniques that have no consequences on detecting other sensitive patterns, as well as non-sensitive patterns required to provide acceptable Quality of Service. Besides, we model the knowledge that might be possessed by potential adversaries to violate privacy and its impacts on the obfuscation procedure. We assessed the performance of APP-CEP in a real-world scenario involving an online retailer’s transactions. Our evaluationresults demonstrate that APP-CEP successfully provides a privacy-utility trade-off. Modeling the background knowledge also effectively prevents adversaries from realizing the modifications in the input streams.</p>
  </span>
  
</div>
</li>
<li>

<div id="pan_et_al:TGDK.1.1.2">
  
    <span class="title">Large Language Models and Knowledge Graphs: Opportunities and Challenges</span>
    <span class="author">
      
        
          
            
              
                Jeff Z. Pan,
              
            
          
        
      
        
          
            
              
                Simon Razniewski,
              
            
          
        
      
        
          
            
              
                Jan-Christoph Kalo,
              
            
          
        
      
        
          
            
              
                Sneha Singhania,
              
            
          
        
      
        
          
            
              
                Jiaoyan Chen,
              
            
          
        
      
        
          
            
              
                Stefan Dietze,
              
            
          
        
      
        
          
            
              
                Hajira Jabeen,
              
            
          
        
      
        
          
            
              
                Janna Omeliyanenko,
              
            
          
        
      
        
          
            
              
                Wen Zhang,
              
            
          
        
      
        
          
            
              
                Matteo Lissandrini,
              
            
          
        
      
        
          
            
              
                Russa Biswas,
              
            
          
        
      
        
          
            
              
                Gerard Melo,
              
            
          
        
      
        
          
            
              
                Angela Bonifati,
              
            
          
        
      
        
          
            
              
                Edlira Vakaj,
              
            
          
        
      
        
          
            
              
                Mauro Dragoni,
              
            
          
        
      
        
          
            
              
                and Damien Graux
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>Transactions on Graph Data and Knowledge</em>
    
    
      2023
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="https://drops.dagstuhl.de/entities/document/10.4230/TGDK.1.1.2" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.4230/TGDK.1.1.2" target="_blank">DOI:10.4230/TGDK.1.1.2</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="veseli-etal-2023-evaluating">
  
    <span class="title">Evaluating the Knowledge Base Completion Potential of GPT</span>
    <span class="author">
      
        
          
            
              
                Blerta Veseli,
              
            
          
        
      
        
          
            
              
                Simon Razniewski,
              
            
          
        
      
        
          
            
              
                Jan-Christoph Kalo,
              
            
          
        
      
        
          
            
              
                and Gerhard Weikum
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Findings of the Association for Computational Linguistics: EMNLP 2023</em>
    
    
      2023
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
  
    [<a href="https://aclanthology.org/2023.findings-emnlp.426" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.18653/v1/2023.findings-emnlp.426" target="_blank">DOI:10.18653/v1/2023.findings-emnlp.426</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Structured knowledge bases (KBs) are an asset for search engines and other applications but are inevitably incomplete. Language models (LMs) have been proposed for unsupervised knowledge base completion (KBC), yet, their ability to do this at scale and with high accuracy remains an open question. Prior experimental studies mostly fall short because they only evaluate on popular subjects, or sample already existing facts from KBs. In this work, we perform a careful evaluation of GPT’s potential to complete the largest public KB: Wikidata. We find that, despite their size and capabilities, models like GPT-3, ChatGPT and GPT-4 do not achieve fully convincing results on this task. Nonetheless, it provides solid improvements over earlier approaches with smaller LMs. In particular, we show that it is feasible to extend Wikidata by 27M facts at 90% precision.</p>
  </span>
  
</div>
</li>
<li>

<div id="krieken2023anesi">
  
    <span class="title">A-NeSI: A Scalable Approximate Method for Probabilistic Neurosymbolic Inference</span>
    <span class="author">
      
        
          
            
              
                Emile Krieken,
              
            
          
        
      
        
          
            
              
                Thiviyan Thanapalasingam,
              
            
          
        
      
        
          
            
              
                Jakub M. Tomczak,
              
            
          
        
      
        
          
            
              
                Frank Van Harmelen,
              
            
          
        
      
        
          
            
              
                and Annette Ten Teije
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Thirty-seventh Conference on Neural Information Processing Systems</em>
    
    
      2023
    
    </span>
  

  <span class="links">
  
  
    [<a href="http://arxiv.org/abs/2212.12393" target="_blank">arXiv</a>]
  
  
  
  
    [<a href="https://openreview.net/forum?id=chlTA9Cegc" target="_blank">Link</a>]
  
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="arakelyan2023adapting">
  
    <span class="title">Adapting Neural Link Predictors for Data-Efficient Complex Query Answering</span>
    <span class="author">
      
        
          
            
              
                Erik Arakelyan,
              
            
          
        
      
        
          
            
              
                Pasquale Minervini,
              
            
          
        
      
        
          
            
              
                Daniel Daza,
              
            
          
        
      
        
          
            
              
                Michael Cochez,
              
            
          
        
      
        
          
            
              
                and Isabelle Augenstein
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Thirty-seventh Conference on Neural Information Processing Systems</em>
    
    
      2023
    
    </span>
  

  <span class="links">
  
  
    [<a href="http://arxiv.org/abs/2301.12313" target="_blank">arXiv</a>]
  
  
  
  
    [<a href="https://openreview.net/forum?id=1G7CBp8o7L" target="_blank">Link</a>]
  
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="Cong2023">
  
    <span class="title">Observatory: Characterizing Embeddings of Relational Tables</span>
    <span class="author">
      
        
          
            
              
                Tianji Cong,
              
            
          
        
      
        
          
            
              
                Madelon Hulsebos,
              
            
          
        
      
        
          
            
              
                Zhenjie Sun,
              
            
          
        
      
        
          
            
              
                Paul Groth,
              
            
          
        
      
        
          
            
              
                and H. V. Jagadish
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>Proceedings of the VLDB Endowment</em>
    
    
      2023
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="http://dx.doi.org/10.14778/3636218.3636237" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.14778/3636218.3636237" target="_blank">DOI:10.14778/3636218.3636237</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="allen_et_al:TGDK.1.1.3">
  
    <span class="title">Knowledge Engineering Using Large Language Models</span>
    <span class="author">
      
        
          
            
              
                Bradley P. Allen,
              
            
          
        
      
        
          
            
              
                Lise Stork,
              
            
          
        
      
        
          
            
              
                and Paul Groth
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>Transactions on Graph Data and Knowledge</em>
    
    
      2023
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="https://drops.dagstuhl.de/entities/document/10.4230/TGDK.1.1.3" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.4230/TGDK.1.1.3" target="_blank">DOI:10.4230/TGDK.1.1.3</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="razniewski_preface:_2023">
  
    <span class="title">Preface: LM-KBC Challenge 2023
Sneha Singhania, Jan-Christoph Kalo, Simon Razniewski, Jeff Z. Pan</span>
    <span class="author">
      
    </span>

    <span class="periodical">
    
      <em>In Joint proceedings of the 1st workshop on Knowledge Base Construction from Pre-Trained Language Models (KBC-LM) and the 2nd challenge on Language Models for Knowledge Base Construction (LM-KBC)</em>
    
    
      2023
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="https://ceur-ws.org/Vol-3577/#paper8" target="_blank">Link</a>]
  
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="li2023do">
  
    <span class="title">Do Instruction-tuned Large Language Models Help with Relation Extraction?</span>
    <span class="author">
      
        
          
            
              
                Xue Li,
              
            
          
        
      
        
          
            
              
                Fina Polat,
              
            
          
        
      
        
          
            
              
                and Paul Groth
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In KBC-LM’23: Knowledge Base Construction from Pre-trained Language Models workshop at ISWC 2023</em>
    
    
      2023
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="https://openreview.net/forum?id=8DiJU0Dyqe" target="_blank">Link</a>]
  
  
  
  
  
  
    [<a href="https://github.com/INDElab/KGC-LLM" target="_blank">Code</a>]
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="li2023challenge">
  
    <span class="title">Knowledge-centric Prompt Composition for Knowledge Base Construction from Pre-trained Language Models</span>
    <span class="author">
      
        
          
            
              
                Xue Li,
              
            
          
        
      
        
          
            
              
                Anthony Hughes,
              
            
          
        
      
        
          
            
              
                Majlinda Llugiqi,
              
            
          
        
      
        
          
            
              
                Fina Polat,
              
            
          
        
      
        
          
            
              
                Paul Groth,
              
            
          
        
      
        
          
            
              
                and Fajar J. Ekaputra
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In KBC-LM’23: Knowledge Base Construction from Pre-trained Language Models workshop at ISWC 2023</em>
    
    
      2023
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="https://lm-kbc.github.io/workshop2023/proceedings/3_Li.pdf" target="_blank">Link</a>]
  
  
  
  
  
  
    [<a href="https://github.com/effyli/lm-kbc/" target="_blank">Code</a>]
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="karabulutsemiim2023">
  
    <span class="title">Semantic Association Rule Learning from Time Series Data and Knowledge Graphs</span>
    <span class="author">
      
        
          
            
              
                Erkan Karabulut,
              
            
          
        
      
        
          
            
              
                Victoria Degeler,
              
            
          
        
      
        
          
            
              
                and Paul Groth1
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In SemIIM’23: 2nd International Workshop on Semantic Industrial Information Modelling co-located with 22nd International Semantic Web Conference (ISWC 2023)</em>
    
    
      2023
    
    </span>
  

  <span class="links">
  
  
    [<a href="http://arxiv.org/abs/2310.07348" target="_blank">arXiv</a>]
  
  
  
  
    [<a href="https://ceur-ws.org/Vol-3647/SemIIM2023_paper_3.pdf" target="_blank">Link</a>]
  
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="10.14778/3611540.3611606">
  
    <span class="title">Mlwhatif: What If You Could Stop Re-Implementing Your Machine Learning Pipeline Analyses over and Over?</span>
    <span class="author">
      
        
          
            
              
                Stefan Grafberger,
              
            
          
        
      
        
          
            
              
                Shubha Guha,
              
            
          
        
      
        
          
            
              
                Paul Groth,
              
            
          
        
      
        
          
            
              
                and Sebastian Schelter
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>Proc. VLDB Endow.</em>
    
    
      2023
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
  
    [<a href="https://doi.org/10.14778/3611540.3611606" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.14778/3611540.3611606" target="_blank">DOI:10.14778/3611540.3611606</a>]
  
  
  
  
  
    [<a href="https://github.com/stefan-grafberger/mlwhatif" target="_blank">Code</a>]
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Software systems that learn from data with machine learning (ML) are used in critical decision-making processes. Unfortunately, real-world experience shows that the pipelines for data preparation, feature encoding and model training in ML systems are often brittle with respect to their input data. As a consequence, data scientists have to run different kinds of data centric what-if analyses to evaluate the robustness and reliability of such pipelines, e.g., with respect to data errors or preprocessing techniques. These what-if analyses follow a common pattern: they take an existing ML pipeline, create a pipeline variant by introducing a small change, and execute this variant to see how the change impacts the pipeline’s output score.We recently proposed mlwhatif, a library that enables data scientists to declaratively specify what-if analyses for an ML pipeline, and to automatically generate, optimize and execute the required pipeline variants. We demonstrate how data scientists can leverage mlwhatif for a variety of pipelines and three different what-if analyses focusing on the robustness of a pipeline against data errors, the impact of data cleaning operations, and the impact of data preprocessing operations on fairness. In particular, we demonstrate step-by-step how mlwhatif generates and optimizes the required execution plans for the pipeline analyses. Our library is publicly available at https://github.com/stefan-grafberger/mlwhatif.</p>
  </span>
  
</div>
</li>
<li>

<div id="polat-etal-2023-improving">
  
    <span class="title">Improving Graph-to-Text Generation Using Cycle Training</span>
    <span class="author">
      
        
          
            
              
                Fina Polat,
              
            
          
        
      
        
          
            
              
                Ilaria Tiddi,
              
            
          
        
      
        
          
            
              
                Paul Groth,
              
            
          
        
      
        
          
            
              
                and Piek Vossen
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Proceedings of the 4th Conference on Language, Data and Knowledge</em>
    
    
      2023
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="https://aclanthology.org/2023.ldk-1.24" target="_blank">Link</a>]
  
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="kdd2023workshop">
  
    <span class="title">Harnessing the Web and Knowledge Graphs for Automated Impact Investing
 Scoring</span>
    <span class="author">
      
        
          
            
              
                Qingzhi Hu,
              
            
          
        
      
        
          
            
              
                Daniel Daza,
              
            
          
        
      
        
          
            
              
                Laurens Swinkels,
              
            
          
        
      
        
          
            
              
                Kristina Usaite,
              
            
          
        
      
        
          
            
              
                Robbert-Jan Hoen,
              
            
          
        
      
        
          
            
              
                and Paul Groth
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In KDD Fragile Earth Workshop</em>
    
    
      2023
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="https://doi.org/10.48550/arXiv.2308.02622" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.48550/arXiv.2308.02622" target="_blank">DOI:10.48550/arXiv.2308.02622</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="10.1093/comnet/cnad025">
  
    <span class="title">An approach for analysing the impact of data integration on complex network diffusion models</span>
    <span class="author">
      
        
          
            
              
                James Nevin,
              
            
          
        
      
        
          
            
              
                Paul Groth,
              
            
          
        
      
        
          
            
              
                and Michael Lees
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>Journal of Complex Networks</em>
    
    
      2023
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="https://doi.org/10.1093/comnet/cnad025" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.1093/comnet/cnad025" target="_blank">DOI:10.1093/comnet/cnad025</a>]
  
  
  
  
  
    [<a href="https://github.com/jim-g-n/nidmod/" target="_blank">Code</a>]
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="10.1145/3583138">
  
    <span class="title">Self-Contained Entity Discovery from Captioned Videos</span>
    <span class="author">
      
        
          
            
              
                Melika Ayoughi,
              
            
          
        
      
        
          
            
              
                Pascal Mettes,
              
            
          
        
      
        
          
            
              
                and Paul Groth
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>ACM Trans. Multimedia Comput. Commun. Appl.</em>
    
    
      2023
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
  
    [<a href="https://doi.org/10.1145/3583138" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.1145/3583138" target="_blank">DOI:10.1145/3583138</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>This article introduces the task of visual named entity discovery in videos without the need for task-specific supervision or task-specific external knowledge sources. Assigning specific names to entities (e.g., faces, scenes, or objects) in video frames is a long-standing challenge. Commonly, this problem is addressed as a supervised learning objective by manually annotating entities with labels. To bypass the annotation burden of this setup, several works have investigated the problem by utilizing external knowledge sources such as movie databases. While effective, such approaches do not work when task-specific knowledge sources are not provided and can only be applied to movies and TV series. In this work, we take the problem a step further and propose to discover entities in videos from videos and corresponding captions or subtitles. We introduce a three-stage method where we (i) create bipartite entity-name graphs from frame–caption pairs, (ii) find visual entity agreements, and (iii) refine the entity assignment through entity-level prototype construction. To tackle this new problem, we outline two new benchmarks, SC-Friends and SC-BBT, based on the Friends and Big Bang Theory TV series. Experiments on the benchmarks demonstrate the ability of our approach to discover which named entity belongs to which face or scene, with an accuracy close to a supervised oracle, just from the multimodal information present in videos. Additionally, our qualitative examples show the potential challenges of self-contained discovery of any visual entity for future work. The code and the data are available on GitHub.1</p>
  </span>
  
</div>
</li>
<li>

<div id="Daga2023">
  
    <span class="title">Data journeys: Explaining AI workflows through abstraction</span>
    <span class="author">
      
        
          
            
              
                Enrico Daga,
              
            
          
        
      
        
          
            
              
                and Paul Groth
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>Semantic Web</em>
    
    
      2023
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
  
    [<a href="https://doi.org/10.3233/sw-233407" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.3233/sw-233407" target="_blank">DOI:10.3233/sw-233407</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>"Artificial intelligence systems are not simply built on a single dataset or trained model. Instead, they are made by complex data science workflows involving multiple datasets, models, preparation scripts, and algorithms. Given this complexity, in order to understand these AI systems, we need to provide explanations of their functioning at higher levels of abstraction. To tackle this problem, we focus on the extraction and representation of data journeys from these workflows. A data journey is a multi-layered semantic representation of data processing activity linked to data science code and assets. We propose an ontology to capture the essential elements of a data journey and an approach to extract such data journeys. Using a corpus of Python notebooks from Kaggle, we show that we are able to capture high-level semantic data flow that is more compact than using the code structure itself. Furthermore, we show that introducing an intermediate knowledge graph representation outperforms models that rely only on the code itself. Finally, we report on a user survey to reflect on the challenges and opportunities presented by computational data journeys for explainable AI."</p>
  </span>
  
</div>
</li>
<li>

<div id="10.1145/3589273">
  
    <span class="title">Automating and Optimizing Data-Centric What-If Analyses on Native Machine Learning Pipelines</span>
    <span class="author">
      
        
          
            
              
                Stefan Grafberger,
              
            
          
        
      
        
          
            
              
                Paul Groth,
              
            
          
        
      
        
          
            
              
                and Sebastian Schelter
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>Proc. ACM Manag. of Data</em>
    
    
      2023
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
  
    [<a href="https://doi.org/10.1145/3589273" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.1145/3589273" target="_blank">DOI:10.1145/3589273</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Software systems that learn from data with machine learning (ML) are used in critical decision-making processes. Unfortunately, real-world experience shows that the pipelines for data preparation, feature encoding and model training in ML systems are often brittle with respect to their input data. As a consequence, data scientists have to run different kinds of data centric what-if analyses to evaluate the robustness and reliability of such pipelines, e.g., with respect to data errors or preprocessing techniques. These what-if analyses follow a common pattern: they take an existing ML pipeline, create a pipeline variant by introducing a small change, and execute this pipeline variant to see how the change impacts the pipeline’s output score. The application of existing analysis techniques to ML pipelines is technically challenging as they are hard to integrate into existing pipeline code and their execution introduces large overheads due to repeated work.We propose mlwhatif to address these integration and efficiency challenges for data-centric what-if analyses on ML pipelines. mlwhatif enables data scientists to declaratively specify what-if analyses for an ML pipeline, and to automatically generate, optimize and execute the required pipeline variants. Our approach employs pipeline patches to specify changes to the data, operators and models of a pipeline. Based on these patches, we define a multi-query optimizer for efficiently executing the resulting pipeline variants jointly, with four subsumption-based optimization rules. Subsequently, we detail how to implement the pipeline variant generation and optimizer of mlwhatif. For that, we instrument native ML pipelines written in Python to extract dataflow plans with re-executable operators.We experimentally evaluate mlwhatif, and find that its speedup scales linearly with the number of pipeline variants in applicable cases, and is invariant to the input data size. In end-to-end experiments with four analyses on more than 60 pipelines, we show speedups of up to 13x compared to sequential execution, and find that the speedup is invariant to the model and featurization in the pipeline. Furthermore, we confirm the low instrumentation overhead of mlwhatif.</p>
  </span>
  
</div>
</li>
<li>

<div id="10.1145/3588710">
  
    <span class="title">GitTables: A Large-Scale Corpus of Relational Tables</span>
    <span class="author">
      
        
          
            
              
                Madelon Hulsebos,
              
            
          
        
      
        
          
            
              
                Çagatay Demiralp,
              
            
          
        
      
        
          
            
              
                and Paul Groth
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>Proc. ACM Manag. Data</em>
    
    
      2023
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
  
    [<a href="https://doi.org/10.1145/3588710" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.1145/3588710" target="_blank">DOI:10.1145/3588710</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>The success of deep learning has sparked interest in improving relational table tasks, like data preparation and search, with table representation models trained on large table corpora. Existing table corpora primarily contain tables extracted from HTML pages, limiting the capability to represent offline database tables. To train and evaluate high-capacity models for applications beyond the Web, we need resources with tables that resemble relational database tables. Here we introduce GitTables, a corpus of 1M relational tables extracted from GitHub. Our continuing curation aims at growing the corpus to at least 10M tables. Analyses of GitTables show that its structure, content, and topical coverage differ significantly from existing table corpora. We annotate table columns in GitTables with semantic types, hierarchical relations and descriptions from Schema.org and DBpedia. The evaluation of our annotation pipeline on the T2Dv2 benchmark illustrates that our approach provides results on par with human annotations. We present three applications of GitTables, demonstrating its value for learned semantic type detection models, schema completion methods, and benchmarks for table-to-KG matching, data search, and preparation. We make the corpus and code available at https://gittables.github.io.</p>
  </span>
  
</div>
</li>
<li>

<div id="delouee2023">
  
    <span class="title">AQuA-CEP: Adaptive Quality-Aware Complex Event Processing in the Internet of Things</span>
    <span class="author">
      
        
          
            
              
                Majid Lotfian Delouee,
              
            
          
        
      
        
          
            
              
                Boris Koldehofe,
              
            
          
        
      
        
          
            
              
                and Viktoriya Degeler
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In The 17th ACM International Conference on Distributed Event-Based Systems (DEBS 2023)</em>
    
    
      2023
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
  
    [<a href="https://2023.debs.org/" target="_blank">Link</a>]
  
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Sensory data profoundly influences the quality of detected events in a distributed complex event processing system (DCEP). Since each sensor’s status is unstable at runtime, a single sensing assignment is often insufficient to fulfill the consumer’s quality requirements. In this paper, we study in the context of AQuA-CEP the problem of dynamic quality monitoring and adaptation of complex event processing by active integration of suitable data sources. To support this, in AQuA-CEP, queries to detect complex events are supplemented with consumer-definable quality policies that are evaluated and used to autonomously select (or even configure) suitable data sources of the sensing infrastructure. In addition, we studied different forms of expressing quality policies and analyzed how it affects the quality monitoring process. Various modes of evaluating and applying quality-related adaptations and their impacts on correlation efficiency are addressed, too. We assessed the performance of AQuA-CEP in IoT scenarios by utilizing the notion of the quality policy alongside the query processing adaptation using knowledge derived from quality monitoring. The results show that AQuA-CEP can improve the performance of DCEP systems in terms of the quality of results while fulfilling the consumer’s quality requirements. Quality-based adaptation can also increase the network’s lifetime by optimizing the sensor’s energy consumption due to efficient data source selection.</p>
  </span>
  
</div>
</li>
<li>

<div id="Karabulut2023">
  
    <span class="title">An Analysis of Machine Learning-Based Semantic Matchmaking</span>
    <span class="author">
      
        
          
            
              
                Erkan Karabulut,
              
            
          
        
      
        
          
            
              
                and Rute C. Sofia
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>IEEE Access</em>
    
    
      2023
    
    </span>
  

  <span class="links">
  
  
  
  
  
  
    [<a href="http://doi.org/10.1109/ACCESS.2023.3259360" target="_blank">DOI:10.1109/ACCESS.2023.3259360</a>]
  
  
  
  
  
    [<a href="https://git.fortiss.org/iiot_external/tsmatch/" target="_blank">Code</a>]
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="10.1145/3576840.3578278">
  
    <span class="title">How to Make an Outlier? Studying the Effect of Presentational Features on the Outlierness of Items in Product Search Results</span>
    <span class="author">
      
        
          
            
              
                Fatemeh Sarvi,
              
            
          
        
      
        
          
            
              
                Mohammad Aliannejadi,
              
            
          
        
      
        
          
            
              
                Sebastian Schelter,
              
            
          
        
      
        
          
            
              
                and Maarten Rijke
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Proceedings of the 2023 Conference on Human Information Interaction and Retrieval</em>
    
    
      2023
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
  
    [<a href="https://doi.org/10.1145/3576840.3578278" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.1145/3576840.3578278" target="_blank">DOI:10.1145/3576840.3578278</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>In two-sided marketplaces, items compete for attention from users since attention translates to revenue for suppliers. Item exposure is an indication of the amount of attention that items receive from users in a ranking. It can be influenced by factors like position bias. Recent work suggests that another phenomenon related to inter-item dependencies may also affect item exposure, viz. outlier items in the ranking. Hence, a deeper understanding of outlier items is crucial to determining an item’s exposure distribution. In this work, we study the impact of different presentational e-commerce features on users’ perception of outlierness of an item in a search result page. Informed by visual search literature, we design a set of crowdsourcing tasks where we compare the observability of three main features, viz. price, star rating, and discount tag. We find that various factors affect item outlierness, namely, visual complexity (e.g., shape, color), discriminative item features, and value range. In particular, we observe that a distinctive visual feature such as a colored discount tag can attract users’ attention much easier than a high price difference, simply because of visual characteristics that are easier to spot. Moreover, we see that the magnitude of deviations in all features affects the task complexity, such that when the similarity between outlier and non-outlier items increases, the task becomes more difficult.</p>
  </span>
  
</div>
</li>
<li>

<div id="Gregory2023">
  
    <span class="title">The Mysterious User of Research Data: Knitting Together Science and Technology Studies with Information and Computer Science</span>
    <span class="author">
      
        
          
            
              
                Kathleen Gregory,
              
            
          
        
      
        
          
            
              
                Paul Groth,
              
            
          
        
      
        
          
            
              
                Andrea Scharnhorst,
              
            
          
        
      
        
          
            
              
                and Sally Wyatt
              
            
          
        
      
    </span>

    <span class="periodical">
    
    
      2023
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
  
    [<a href="https://doi.org/10.1007/978-3-031-11108-2_11" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.1007/978-3-031-11108-2_11" target="_blank">DOI:10.1007/978-3-031-11108-2_11</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Open, accessible, and standardized research data are seen as essential scaffolding for open science. To support this vision, data repositories and scientific publishers have developed new tools to facilitate data discovery while funders and policy makers have implemented open science and data management policies. Users are often invoked as central to these efforts. Despite this stated focus, the concept of ‘user’ often remains an abstraction, visible only via anonymous ensembles of click behavior or data management plans. This chapter reports and reflects on a project which draws on science and technology studies (STS) to open up the black box of research data use, bridging the gap between designers of data search systems and researchers who (re-)use both data and these systems in their actual practices. Quantitative and qualitative studies conducted in the course of this project will be drawn upon to demonstrate the insights gained from an interdisciplinary approach.</p>
  </span>
  
</div>
</li>
<li>

<div id="DBLP:conf/semweb/2022semtab">
  
    <span class="title">SemTab 2022: Proceedings of the Semantic Web Challenge on Tabular Data to Knowledge
 Graph Matching, co-located with the 21st International
 Semantic Web Conference, ISWC 2022, Virtual conference, October
 23-27, 2022</span>
    <span class="author">
      
    </span>

    <span class="periodical">
    
    
      2023
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="http://ceur-ws.org/Vol-3320" target="_blank">Link</a>]
  
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="10411709">
  
    <span class="title">E2EG: End-to-End Node Classification Using Graph Topology and Text-based Node Attributes</span>
    <span class="author">
      
        
          
            
              
                Tu Anh Dinh,
              
            
          
        
      
        
          
            
              
                Jeroen Boef,
              
            
          
        
      
        
          
            
              
                Joran Cornelisse,
              
            
          
        
      
        
          
            
              
                and Paul Groth
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In 2023 IEEE International Conference on Data Mining Workshops (ICDMW)</em>
    
    
      2023
    
    </span>
  

  <span class="links">
  
  
  
  
  
  
    [<a href="http://doi.org/10.1109/ICDMW60847.2023.00142" target="_blank">DOI:10.1109/ICDMW60847.2023.00142</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="grafbergertowards2023">
  
    <span class="title">Towards Declarative Systems for Data-Centric Machine Learning</span>
    <span class="author">
      
        
          
            
              
                Stefan Grafberger,
              
            
          
        
      
        
          
            
              
                Bojan Karlaš,
              
            
          
        
      
        
          
            
              
                Paul Groth,
              
            
          
        
      
        
          
            
              
                and Sebastian Schelter
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Proceedings of the Data-Centric Machine Learning Research work- shop (DMLR) at ICML, 2023</em>
    
    
      2023
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="https://dmlr.ai/assets/accepted-papers/41/CameraReady/autodc.pdf" target="_blank">Link</a>]
  
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="DBLP:series/faia/CochezAABD0MNR23">
  
    <span class="title">Approximate Answering of Graph Queries</span>
    <span class="author">
      
        
          
            
              
                Michael Cochez,
              
            
          
        
      
        
          
            
              
                Dimitrios Alivanistos,
              
            
          
        
      
        
          
            
              
                Erik Arakelyan,
              
            
          
        
      
        
          
            
              
                Max Berrendorf,
              
            
          
        
      
        
          
            
              
                Daniel Daza,
              
            
          
        
      
        
          
            
              
                Mikhail Galkin,
              
            
          
        
      
        
          
            
              
                Pasquale Minervini,
              
            
          
        
      
        
          
            
              
                Mathias Niepert,
              
            
          
        
      
        
          
            
              
                and Hongyu Ren
              
            
          
        
      
    </span>

    <span class="periodical">
    
    
      2023
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="https://doi.org/10.3233/FAIA230149" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.3233/FAIA230149" target="_blank">DOI:10.3233/FAIA230149</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="DBLP:conf/cikm/XiongNDC23">
  
    <span class="title">Reasoning beyond Triples: Recent Advances in Knowledge Graph Embeddings</span>
    <span class="author">
      
        
          
            
              
                Bo Xiong,
              
            
          
        
      
        
          
            
              
                Mojtaba Nayyeri,
              
            
          
        
      
        
          
            
              
                Daniel Daza,
              
            
          
        
      
        
          
            
              
                and Michael Cochez
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Proceedings of the 32nd ACM International Conference on Information
 and Knowledge Management, CIKM 2023, Birmingham, United Kingdom,
 October 21-25, 2023</em>
    
    
      2023
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="https://doi.org/10.1145/3583780.3615294" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.1145/3583780.3615294" target="_blank">DOI:10.1145/3583780.3615294</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="DBLP:conf/cidr/Schelter23">
  
    <span class="title">Reconstructing and Querying ML Pipeline Intermediates</span>
    <span class="author">
      
        
          
            Sebastian Schelter
          
        
      
    </span>

    <span class="periodical">
    
      <em>In 13th Conference on Innovative Data Systems Research, CIDR 2023,
 Amsterdam, The Netherlands, January 8-11, 2023</em>
    
    
      2023
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="https://www.cidrdb.org/cidr2023/papers/p31-schelter.pdf" target="_blank">Link</a>]
  
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="Akkerman2023">
  
    <span class="title">Figure of Speech Detection and Generation as a Service in IDN Authoring Support</span>
    <span class="author">
      
        
          
            
              
                Simon Akkerman,
              
            
          
        
      
        
          
            
              
                and Frank Nack
              
            
          
        
      
    </span>

    <span class="periodical">
    
    
      2023
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="http://dx.doi.org/10.1007/978-3-031-47658-7_8" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.1007/978-3-031-47658-7_8" target="_blank">DOI:10.1007/978-3-031-47658-7_8</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="10.1007/978-3-031-45728-9_2">
  
    <span class="title">Empowering Machine Learning Development with Service-Oriented Computing Principles</span>
    <span class="author">
      
        
          
            
              
                Mostafa Hadadian Nejad Yousefi,
              
            
          
        
      
        
          
            
              
                Viktoriya Degeler,
              
            
          
        
      
        
          
            
              
                and Alexander Lazovik
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Service-Oriented Computing</em>
    
    
      2023
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
  
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Despite software industries’ successful utilization of Service-Oriented Computing (SOC) to streamline software development, machine learning (ML) development has yet to fully integrate these practices. This disparity can be attributed to multiple factors, such as the unique challenges inherent to ML development and the absence of a unified framework for incorporating services into this process. In this paper, we shed light on the disparities between services-oriented computing and machine learning development. We propose “Everything as a Module” (XaaM), a framework designed to encapsulate every ML artifacts including models, code, data, and configurations as individual modules, to bridge this gap. We propose a set of additional steps that need to be taken to empower machine learning development using services-oriented computing via an architecture that facilitates efficient management and orchestration of complex ML systems. By leveraging the best practices of services-oriented computing, we believe that machine learning development can achieve a higher level of maturity, improve the efficiency of the development process, and ultimately, facilitate the more effective creation of machine learning applications.</p>
  </span>
  
</div>
</li>
<li>

<div id="DBLP:conf/semweb/HassanzadehAECC23">
  
    <span class="title">Results of SemTab 2023</span>
    <span class="author">
      
        
          
            
              
                Oktie Hassanzadeh,
              
            
          
        
      
        
          
            
              
                Nora Abdelmageed,
              
            
          
        
      
        
          
            
              
                Vasilis Efthymiou,
              
            
          
        
      
        
          
            
              
                Jiaoyan Chen,
              
            
          
        
      
        
          
            
              
                Vincenzo Cutrona,
              
            
          
        
      
        
          
            
              
                Madelon Hulsebos,
              
            
          
        
      
        
          
            
              
                Ernesto Jiménez-Ruiz,
              
            
          
        
      
        
          
            
              
                Aamod Khatiwada,
              
            
          
        
      
        
          
            
              
                Keti Korini,
              
            
          
        
      
        
          
            
              
                Benno Kruit,
              
            
          
        
      
        
          
            
              
                Juan Sequeda,
              
            
          
        
      
        
          
            
              
                and Kavitha Srinivas
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Proceedings of the Semantic Web Challenge on Tabular Data to Knowledge
 Graph Matching, SemTab 2023, co-located with the 22nd International
 Semantic Web Conference, ISWC 2023, Athens, Greece, November 6-10,
 2023</em>
    
    
      2023
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="https://ceur-ws.org/Vol-3557/paper0.pdf" target="_blank">Link</a>]
  
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="cong2023introducing">
  
    <span class="title">Introducing the Observatory Library for End-to-End Table Embedding Inference</span>
    <span class="author">
      
        
          
            
              
                Tianji Cong,
              
            
          
        
      
        
          
            
              
                Zhenjie Sun,
              
            
          
        
      
        
          
            
              
                Paul Groth,
              
            
          
        
      
        
          
            
              
                H. Jagadish,
              
            
          
        
      
        
          
            
              
                and Madelon Hulsebos
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In NeurIPS 2023 Second Table Representation Learning Workshop</em>
    
    
      2023
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="https://openreview.net/forum?id=JIrTIMI5Yd" target="_blank">Link</a>]
  
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="10184590">
  
    <span class="title">Automated Data Cleaning Can Hurt Fairness in Machine Learning-based Decision Making</span>
    <span class="author">
      
        
          
            
              
                Shubha Guha,
              
            
          
        
      
        
          
            
              
                Falaah Arif Khan,
              
            
          
        
      
        
          
            
              
                Julia Stoyanovich,
              
            
          
        
      
        
          
            
              
                and Sebastian Schelter
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In 2023 IEEE 39th International Conference on Data Engineering (ICDE)</em>
    
    
      2023
    
    </span>
  

  <span class="links">
  
  
  
  
  
  
    [<a href="http://doi.org/10.1109/ICDE55515.2023.00303" target="_blank">DOI:10.1109/ICDE55515.2023.00303</a>]
  
  
  
  
  
    [<a href="https://github.com/amsterdata/demodq" target="_blank">Code</a>]
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="10.1145/3539618.3591989">
  
    <span class="title">Forget Me Now: Fast and Exact Unlearning in Neighborhood-Based Recommendation</span>
    <span class="author">
      
        
          
            
              
                Sebastian Schelter,
              
            
          
        
      
        
          
            
              
                Mozhdeh Ariannezhad,
              
            
          
        
      
        
          
            
              
                and Maarten Rijke
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval</em>
    
    
      2023
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
  
    [<a href="https://doi.org/10.1145/3539618.3591989" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.1145/3539618.3591989" target="_blank">DOI:10.1145/3539618.3591989</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Modern search and recommendation systems are optimized using logged interaction data. There is increasing societal pressure to enable users of such systems to have some of their data deleted from those systems. This paper focuses on "unlearning" such user data from neighborhood-based recommendation models on sparse, high-dimensional datasets. We present caboose, a custom top-k index for such models, which enables fast and exact deletion of user interactions. We experimentally find that caboose provides competitive index building times, makes sub-second unlearning possible (even for a large index built from one million users and 256 million interactions), and, when integrated into three state-of-the-art next-basket recommendation models, allows users to effectively adjust their predictions to remove sensitive items.</p>
  </span>
  
</div>
</li>
<li>

<div id="10.1007/978-3-031-35995-8_35">
  
    <span class="title">Data Integration Landscapes: The Case for Non-optimal Solutions in Network Diffusion Models</span>
    <span class="author">
      
        
          
            
              
                James Nevin,
              
            
          
        
      
        
          
            
              
                Paul Groth,
              
            
          
        
      
        
          
            
              
                and Michael Lees
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Computational Science – ICCS 2023</em>
    
    
      2023
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
  
  
    [<a href="http://doi.org/10.1007/978-3-031-35995-8_35" target="_blank">DOI:10.1007/978-3-031-35995-8_35</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>The successful application of computational models presupposes access to accurate, relevant, and representative datasets. The growth of public data, and the increasing practice of data sharing and reuse, emphasises the importance of data provenance and increases the need for modellers to understand how data processing decisions might impact model output. One key step in the data processing pipeline is that of data integration and entity resolution, where entities are matched across disparate datasets. In this paper, we present a new formulation of data integration in complex networks that incorporates integration uncertainty. We define an approach for understanding how different data integration setups can impact the results of network diffusion models under this uncertainty, allowing one to systematically characterise potential model outputs in order to create an output distribution that provides a more comprehensive picture.</p>
  </span>
  
</div>
</li>
<li>

<div id="10.1145/3555041.3589682">
  
    <span class="title">Proactively Screening Machine Learning Pipelines with ARGUSEYES</span>
    <span class="author">
      
        
          
            
              
                Sebastian Schelter,
              
            
          
        
      
        
          
            
              
                Stefan Grafberger,
              
            
          
        
      
        
          
            
              
                Shubha Guha,
              
            
          
        
      
        
          
            
              
                Bojan Karlas,
              
            
          
        
      
        
          
            
              
                and Ce Zhang
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Companion of the 2023 International Conference on Management of Data</em>
    
    
      2023
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
  
    [<a href="https://doi.org/10.1145/3555041.3589682" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.1145/3555041.3589682" target="_blank">DOI:10.1145/3555041.3589682</a>]
  
  
  
  
  
  
  
    [<a href="" target="_blank"> <img class="emoji" title=":tada:" alt=":tada:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f389.png" height="20" width="20"> 2nd Place Demo </a>]
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Software systems that learn from data with machine learning (ML) are ubiquitous. ML pipelines in these applications often suffer from a variety of data-related issues, such as data leakage, label errors or fairness violations, which require reasoning about complex dependencies between their inputs and outputs. These issues are usually only detected in hindsight after deployment, after they caused harm in production. We demonstrate ArgusEyes, a system which enables data scientists to proactively screen their ML pipelines for data-related issues as part of continuous integration. ArgusEyes instruments, executes and screens ML pipelines for declaratively specified pipeline issues, and analyzes data artifacts and their provenance to catch potential problems early before deployment to production. We demonstrate our system for three scenarios: detecting mislabeled images in a computer vision pipeline, spotting data leakage in a price prediction pipeline, and addressing fairness violations in a credit scoring pipeline.</p>
  </span>
  
</div>
</li>
<li>

<div id="10.1145/3555041.3590819">
  
    <span class="title">Seventh Workshop on Data Management for End-to-End Machine Learning (DEEM)</span>
    <span class="author">
      
        
          
            
              
                Matthias Boehm,
              
            
          
        
      
        
          
            
              
                Madelon Hulsebos,
              
            
          
        
      
        
          
            
              
                Shreya Shankar,
              
            
          
        
      
        
          
            
              
                and Paroma Varma
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Companion of the 2023 International Conference on Management of Data</em>
    
    
      2023
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
  
    [<a href="https://doi.org/10.1145/3555041.3590819" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.1145/3555041.3590819" target="_blank">DOI:10.1145/3555041.3590819</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>The DEEM’23 workshop (Data Management for End-to-End Machine Learning) is held on Sunday June 18th, in conjunction with SIGMOD/PODS 2023. DEEM brings together researchers and practitioners at the intersection of applied machine learning, data management and systems research, with the goal to discuss the arising data management issues in ML application scenarios. The workshop solicits regular research papers (10 pages) describing preliminary and ongoing research results, including industrial experience reports of end-to-end ML deployments, related to DEEM topics. In addition, DEEM 2023 has a category for short papers (4 pages) as a forum for sharing interesting use cases, problems, datasets, benchmarks, visionary ideas, system designs, preliminary results, and descriptions of system components and tools related to end-to-end ML pipelines. The workshop received 13 high-quality submissions on diverse topics relevant to DEEM, of which 6 regular papers and 7 short papers.</p>
  </span>
  
</div>
</li>
<li>

<div id="10.1145/3555041.3589411">
  
    <span class="title">Models and Practice of Neural Table Representations</span>
    <span class="author">
      
        
          
            
              
                Madelon Hulsebos,
              
            
          
        
      
        
          
            
              
                Xiang Deng,
              
            
          
        
      
        
          
            
              
                Huan Sun,
              
            
          
        
      
        
          
            
              
                and Paolo Papotti
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Companion of the 2023 International Conference on Management of Data</em>
    
    
      2023
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
  
    [<a href="https://doi.org/10.1145/3555041.3589411" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.1145/3555041.3589411" target="_blank">DOI:10.1145/3555041.3589411</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>In the last few years, the natural language processing community witnessed advances in neural representations of free-form text with transformer-based language models (LMs). Given the importance of knowledge available in relational tables, recent research efforts extend LMs by developing neural representations for tabular data. In this tutorial, we present these proposals with three main goals. First, we aim at introducing the potentials and limitations of current models to a database audience. Second, we want the attendees to see the benefit of such line of work in a large variety of data applications. Third, we would like to empower the audience with a new set of tools and to inspire them to tackle some of the important directions for neural table representations, including model and system design, evaluation, application and deployment. To achieve these goals, the tutorial is organized in two parts. The first part covers the background for neural table representations, including a survey of the most important systems. The second part is designed as a hands-on session, where attendees will use their laptop to explore this new framework and test neural models involving text and tabular data.</p>
  </span>
  
</div>
</li>
<li>

<div id="10.1145/3543873.3587557">
  
    <span class="title">Provenance Tracking for End-to-End Machine Learning Pipelines</span>
    <span class="author">
      
        
          
            
              
                Stefan Grafberger,
              
            
          
        
      
        
          
            
              
                Paul Groth,
              
            
          
        
      
        
          
            
              
                and Sebastian Schelter
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Companion Proceedings of the ACM Web Conference 2023</em>
    
    
      2023
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="https://doi.org/10.1145/3543873.3587557" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.1145/3543873.3587557" target="_blank">DOI:10.1145/3543873.3587557</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="jullien2023a">
  
    <span class="title">A Simulation Environment and Reinforcement Learning Method for Waste Reduction</span>
    <span class="author">
      
        
          
            
              
                Sami Jullien,
              
            
          
        
      
        
          
            
              
                Mozhdeh Ariannezhad,
              
            
          
        
      
        
          
            
              
                Paul Groth,
              
            
          
        
      
        
          
            
              
                and Maarten Rijke
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>Transactions on Machine Learning Research</em>
    
    
      2023
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="https://openreview.net/forum?id=KSvr8A62MD" target="_blank">Link</a>]
  
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="groth_et_al:DagRep.12.9.60">
  
    <span class="title">Knowledge Graphs and their Role in the Knowledge Engineering of the 21st Century (Dagstuhl Seminar 22372)</span>
    <span class="author">
      
        
          
            
              
                Paul Groth,
              
            
          
        
      
        
          
            
              
                Elena Simperl,
              
            
          
        
      
        
          
            
              
                Marieke Erp,
              
            
          
        
      
        
          
            
              
                and Denny Vrandečić
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>Dagstuhl Reports</em>
    
    
      2023
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="https://drops.dagstuhl.de/opus/volltexte/2023/17810" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.4230/DagRep.12.9.60" target="_blank">DOI:10.4230/DagRep.12.9.60</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="10.1145/3583678.3603278">
  
    <span class="title">Poster: Towards Pattern-Level Privacy Protection in Distributed Complex Event Processing</span>
    <span class="author">
      
        
          
            
              
                Majid Lotfian Delouee,
              
            
          
        
      
        
          
            
              
                Boris Koldehofe,
              
            
          
        
      
        
          
            
              
                and Viktoriya Degeler
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Proceedings of the 17th ACM International Conference on Distributed and Event-Based Systems</em>
    
    
      2023
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
  
    [<a href="https://doi.org/10.1145/3583678.3603278" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.1145/3583678.3603278" target="_blank">DOI:10.1145/3583678.3603278</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>In event processing systems, detected event patterns can reveal privacy-sensitive information. In this paper, we propose and discuss how to integrate pattern-level privacy protection in event-based systems. Compared to state-of-the-art approaches, we aim to enforce privacy independent of the particularities of specific operators. We accomplish this by supporting the flexible integration of multiple obfuscation techniques and studying deployment strategies for privacy-enforcing mechanisms. In addition, we share ideas on how to model the adversary’s knowledge to select appropriate obfuscation techniques for the discussed deployment strategies. Initial results indicate that flexibly choosing obfuscation techniques and deployment strategies is essential to conceal privacy-sensitive event patterns accurately.</p>
  </span>
  
</div>
</li>
<li>

<div id="prieto2023parameter">
  
    <span class="title">Parameter Efficient Node Classification on Homophilic Graphs</span>
    <span class="author">
      
        
          
            
              
                Lucas Prieto,
              
            
          
        
      
        
          
            
              
                Jeroen Den Boef,
              
            
          
        
      
        
          
            
              
                Paul Groth,
              
            
          
        
      
        
          
            
              
                and Joran Cornelisse
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>Transactions on Machine Learning Research</em>
    
    
      2023
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="https://openreview.net/forum?id=LIT8tjs6rJ" target="_blank">Link</a>]
  
  
  
  
  
  
    [<a href="https://github.com/LucasPrietoAl/GNPD" target="_blank">Code</a>]
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
</ol>

<h3 class="year">2022</h3>
<ol class="bibliography">
<li>

<div id="Thanapalasingam2022">
  
    <span class="title">Relational graph convolutional networks: a closer look</span>
    <span class="author">
      
        
          
            
              
                Thiviyan Thanapalasingam,
              
            
          
        
      
        
          
            
              
                Lucas Berkel,
              
            
          
        
      
        
          
            
              
                Peter Bloem,
              
            
          
        
      
        
          
            
              
                and Paul Groth
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>PeerJ Computer Science</em>
    
    
      2022
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="https://doi.org/10.7717/peerj-cs.1073" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.7717/peerj-cs.1073" target="_blank">DOI:10.7717/peerj-cs.1073</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="harper2022">
  
    <span class="title">Question Answering with Additive Restrictive Training (QuAART): Question Answering for the Rapid Development of New Knowledge Extraction Pipelines</span>
    <span class="author">
      
        
          
            
              
                Corey A. Harper,
              
            
          
        
      
        
          
            
              
                Ron Daniel,
              
            
          
        
      
        
          
            
              
                and Paul Groth
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Knowledge Engineering and Knowledge Management (EKAW)</em>
    
    
      2022
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
  
    [<a href="https://link.springer.com/10.1007/978-3-031-17105-5_4" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.1007/978-3-031-17105-5_4" target="_blank">DOI:10.1007/978-3-031-17105-5_4</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Abstract
 Numerous studies have explored the use of language models and question answering techniques for knowledge extraction. In most cases, these models are trained on data specific to the new task at hand. We hypothesize that using models trained only on generic question answering data (e.g. SQuAD) is a good starting point for domain specific entity extraction. We test this hypothesis, and explore whether the addition of small amounts of training data can help lift model performance. We pay special attention to the use of null answers and unanswerable questions to optimize performance. To our knowledge, no studies have been done to evaluate the effectiveness of this technique. We do so for an end-to-end entity mention detection and entity typing task on HAnDS and FIGER, two common evaluation datasets for fine grained entity recognition. We focus on fine-grained entity recognition because it is challenging scenario, and because the long tail of types in this task highlights the need for entity extraction systems that can deal with new domains and types. To our knowledge, we are the first system beyond those presented in the original FIGER and HAnDS papers to tackle the task in an end-to-end fashion. Using an extremely small sample from the distantly-supervised HAnDS training data – 0.0015%, or less than 500 passages randomly chosen out of 31 million – we produce a CoNNL F1 score of 73.72 for entity detection on FIGER. Our end-to-end detection and typing evaluation produces macro and micro F1s of 45.11 and 54.75, based on the FIGER evaluation metrics. This work provides a foundation for the rapid development of new knowledge extraction pipelines.</p>
  </span>
  
</div>
</li>
<li>

<div id="10.1145/3514221.3517901">
  
    <span class="title">Serenade - Low-Latency Session-Based Recommendation in e-Commerce at Scale</span>
    <span class="author">
      
        
          
            
              
                Barrie Kersbergen,
              
            
          
        
      
        
          
            
              
                Olivier Sprangers,
              
            
          
        
      
        
          
            
              
                and Sebastian Schelter
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Proceedings of the 2022 International Conference on Management of Data</em>
    
    
      2022
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
  
    [<a href="https://ssc.io/pdf/modds003.pdf" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.1145/3514221.3517901" target="_blank">DOI:10.1145/3514221.3517901</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Session-based recommendation predicts the next item with which a user will interact, given a sequence of her past interactions with other items. This machine learning problem targets a core scenario in e-commerce platforms, which aim to recommend interesting items to buy to users browsing the site. Session-based recommenders are difficult to scale due to their exponentially large input space of potential sessions. This impedes offline precomputation of the recommendations, and implies the necessity to maintain state during the online computation of next-item recommendations.We propose VMIS-kNN, an adaptation of a state-of-the-art nearest neighbor approach to session-based recommendation, which leverages a prebuilt index to compute next-item recommendations with low latency in scenarios with hundreds of millions of clicks to search through. Based on this approach, we design and implement the scalable session-based recommender system Serenade, which is in production usage at bol.com, a large European e-commerce platform.We evaluate the predictive performance of VMIS-kNN, and show that Serenade can answer a thousand recommendation requests per second with a 90th percentile latency of less than seven milliseconds in scenarios with millions of items to recommend. Furthermore, we present results from a three week long online A/B test with up to 600 requests per second for 6.5 million distinct items on more than 45 million user sessions from our e-commerce platform. To the best of our knowledge, we provide the first empirical evidence that the superior predictive performance of nearest neighbor approaches to session-based recommendation in offline evaluations translates to superior performance in a real world e-commerce setting.</p>
  </span>
  
</div>
</li>
<li>

<div id="10.1145/3533028.3533303">
  
    <span class="title">Towards Data-Centric What-If Analysis for Native Machine Learning Pipelines</span>
    <span class="author">
      
        
          
            
              
                Stefan Grafberger,
              
            
          
        
      
        
          
            
              
                Paul Groth,
              
            
          
        
      
        
          
            
              
                and Sebastian Schelter
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Proceedings of the Sixth Workshop on Data Management for End-To-End Machine Learning</em>
    
    
      2022
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
  
    [<a href="https://stefan-grafberger.com/mlwhatif-deem.pdf" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.1145/3533028.3533303" target="_blank">DOI:10.1145/3533028.3533303</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>An important task of data scientists is to understand the sensitivity of their models to changes in the data that the models are trained and tested upon. Currently, conducting such data-centric what-if analyses requires significant and costly manual development and testing with the corresponding chance for the introduction of bugs. We discuss the problem of data-centric what-if analysis over whole ML pipelines (including data preparation and feature encoding), propose optimisations that reuse trained models and intermediate data to reduce the runtime of such analysis, and finally conduct preliminary experiments on three complex example pipelines, where our approach reduces the runtime by a factor of up to six.</p>
  </span>
  
</div>
</li>
<li>

<div id="10.1145/3488717">
  
    <span class="title">Responsible Data Management</span>
    <span class="author">
      
        
          
            
              
                Julia Stoyanovich,
              
            
          
        
      
        
          
            
              
                Serge Abiteboul,
              
            
          
        
      
        
          
            
              
                Bill Howe,
              
            
          
        
      
        
          
            
              
                H. V. Jagadish,
              
            
          
        
      
        
          
            
              
                and Sebastian Schelter
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>Communications of the ACM</em>
    
    
      2022
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
  
    [<a href="https://doi.org/10.1145/3488717" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.1145/3488717" target="_blank">DOI:10.1145/3488717</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Perspectives on the role and responsibility of the data-management research community in designing, developing, using, and overseeing automated decision systems.</p>
  </span>
  
</div>
</li>
<li>

<div id="daza-etal-2022-slotgan">
  
    <span class="title">SlotGAN: Detecting Mentions in Text via Adversarial Distant Learning</span>
    <span class="author">
      
        
          
            
              
                Daniel Daza,
              
            
          
        
      
        
          
            
              
                Michael Cochez,
              
            
          
        
      
        
          
            
              
                and Paul Groth
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Proceedings of the Sixth Workshop on Structured Prediction for NLP</em>
    
    
      2022
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
  
    [<a href="https://aclanthology.org/2022.spnlp-1.4" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.18653/v1/2022.spnlp-1.4" target="_blank">DOI:10.18653/v1/2022.spnlp-1.4</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>We present SlotGAN, a framework for training a mention detection model that only requires unlabeled text and a gazetteer. It consists of a generator trained to extract spans from an input sentence, and a discriminator trained to determine whether a span comes from the generator, or from the gazetteer.We evaluate the method on English newswire data and compare it against supervised, weakly-supervised, and unsupervised methods. We find that the performance of the method is lower than these baselines, because it tends to generate more and longer spans, and in some cases it relies only on capitalization. In other cases, it generates spans that are valid but differ from the benchmark. When evaluated with metrics based on overlap, we find that SlotGAN performs within 95% of the precision of a supervised method, and 84% of its recall. Our results suggest that the model can generate spans that overlap well, but an additional filtering mechanism is required.</p>
  </span>
  
</div>
</li>
<li>

<div id="lippe2022citris">
  
    <span class="title">CITRIS: Causal Identifiability from Temporal Intervened Sequences</span>
    <span class="author">
      
        
          
            
              
                Phillip Lippe,
              
            
          
        
      
        
          
            
              
                Sara Magliacane,
              
            
          
        
      
        
          
            
              
                Sindy Löwe,
              
            
          
        
      
        
          
            
              
                Yuki M. Asano,
              
            
          
        
      
        
          
            
              
                Taco Cohen,
              
            
          
        
      
        
          
            
              
                and Efstratios Gavves
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Proceedings of the 39th International Conference on Machine Learning, ICML</em>
    
    
      2022
    
    </span>
  

  <span class="links">
  
  
    [<a href="http://arxiv.org/abs/2202.03169" target="_blank">arXiv</a>]
  
  
  
  
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="10.1145/3486897">
  
    <span class="title">Methods Included</span>
    <span class="author">
      
        
          
            
              
                Michael R. Crusoe,
              
            
          
        
      
        
          
            
              
                Sanne Abeln,
              
            
          
        
      
        
          
            
              
                Alexandru Iosup,
              
            
          
        
      
        
          
            
              
                Peter Amstutz,
              
            
          
        
      
        
          
            
              
                John Chilton,
              
            
          
        
      
        
          
            
              
                Nebojša Tijanić,
              
            
          
        
      
        
          
            
              
                Hervé Ménager,
              
            
          
        
      
        
          
            
              
                Stian Soiland-Reyes,
              
            
          
        
      
        
          
            
              
                Bogdan Gavrilović,
              
            
          
        
      
        
          
            
              
                Carole Goble,
              
            
          
        
      
        
          
            
              
                and  The CWL Community
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>Communications of the ACM</em>
    
    
      2022
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
  
    [<a href="https://doi.org/10.1145/3486897" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.1145/3486897" target="_blank">DOI:10.1145/3486897</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Standardizing computational reuse and portability with the Common Workflow Language.</p>
  </span>
  
</div>
</li>
<li>

<div id="10.1162/dint_a_00135">
  
    <span class="title">Making Canonical Workflow Building Blocks Interoperable across Workflow Languages</span>
    <span class="author">
      
        
          
            
              
                Stian Soiland-Reyes,
              
            
          
        
      
        
          
            
              
                Genís Bayarri,
              
            
          
        
      
        
          
            
              
                Pau Andrio,
              
            
          
        
      
        
          
            
              
                Robin Long,
              
            
          
        
      
        
          
            
              
                Douglas Lowe,
              
            
          
        
      
        
          
            
              
                Ania Niewielska,
              
            
          
        
      
        
          
            
              
                Adam Hospital,
              
            
          
        
      
        
          
            
              
                and Paul Groth
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>Data Intelligence</em>
    
    
      2022
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
  
    [<a href="https://doi.org/10.1162/dint_a_00135" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.1162/dint_a_00135" target="_blank">DOI:10.1162/dint_a_00135</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>We introduce the concept of Canonical Workflow Building Blocks (CWBB), a methodology of describing and wrapping computational tools, in order for them to be utilised in a reproducible manner from multiple workflow languages and execution platforms. The concept is implemented and demonstrated with the BioExcel Building Blocks library (BioBB), a collection of tool wrappers in the field of computational biomolecular simulation. Interoperability across different workflow languages is showcased through a protein Molecular Dynamics setup transversal workflow, built using this library and run with 5 different Workflow Manager Systems (WfMS). We argue such practice is a necessary requirement for FAIR Computational Workflows and an element of Canonical Workflow Frameworks for Research (CWFR) in order to improve widespread adoption and reuse of computational methods across workflow language barriers.</p>
  </span>
  
</div>
</li>
<li>

<div id="schelterspecialissue">
  
    <span class="title">Letter from the Special Issue Editor</span>
    <span class="author">
      
        
          
            Sebastian Schelter
          
        
      
    </span>

    <span class="periodical">
    
      <em>IEEE Data Engineering Bulletin (Special issue on Directions Towards GDPR-Compliant Data Systems and Applications)</em>
    
    
      2022
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="http://sites.computer.org/debull/A22mar/p2.pdf" target="_blank">Link</a>]
  
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="10.1145/3522586">
  
    <span class="title">Defining a Knowledge Graph Development Process Through a Systematic Review</span>
    <span class="author">
      
        
          
            
              
                Gytundefined Tamašauskaitundefined,
              
            
          
        
      
        
          
            
              
                and Paul Groth
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>ACM Transactios on Software Engineering and Methodology</em>
    
    
      2022
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
  
    [<a href="https://doi.org/10.1145/3522586" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.1145/3522586" target="_blank">DOI:10.1145/3522586</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Knowledge graphs are widely used in industry and studied within the academic community. However, the models applied in the development of knowledge graphs vary. Analysing and providing a synthesis of the commonly used approaches to knowledge graph development would provide researchers and practitioners a better understanding of the overall process and methods involved. Hence, this paper aims to define the overall process of knowledge graph development and its key constituent steps. For this purpose, a systematic review and a conceptual analysis of the literature was conducted. The resulting process was compared to case studies to evaluate its applicability. The proposed process suggests a unified approach and provides guidance for both researchers and practitioners when constructing and managing knowledge graphs.</p>
  </span>
  
</div>
</li>
<li>

<div id="rocrate2022">
  
    <span class="title">Packaging research artefacts with RO-Crate</span>
    <span class="author">
      
        
          
            
              
                Stian Soiland-Reyes,
              
            
          
        
      
        
          
            
              
                Peter Sefton,
              
            
          
        
      
        
          
            
              
                Mercè Crosas,
              
            
          
        
      
        
          
            
              
                Leyla Jael Castro,
              
            
          
        
      
        
          
            
              
                Frederik Coppens,
              
            
          
        
      
        
          
            
              
                José M. Fernández,
              
            
          
        
      
        
          
            
              
                Daniel Garijo,
              
            
          
        
      
        
          
            
              
                Björn Grüning,
              
            
          
        
      
        
          
            
              
                Marco La Rosa,
              
            
          
        
      
        
          
            
              
                Simone Leo,
              
            
          
        
      
        
          
            
              
                and  al.
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>Data Science</em>
    
    
      2022
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="https://doi.org/10.3233/DS-210053" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.3233/DS-210053" target="_blank">DOI:10.3233/DS-210053</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="Grafberger2022">
  
    <span class="title">Data distribution debugging in machine learning pipelines</span>
    <span class="author">
      
        
          
            
              
                Stefan Grafberger,
              
            
          
        
      
        
          
            
              
                Paul Groth,
              
            
          
        
      
        
          
            
              
                Julia Stoyanovich,
              
            
          
        
      
        
          
            
              
                and Sebastian Schelter
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>The VLDB Journal</em>
    
    
      2022
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="https://stefan-grafberger.com/mlinspect-journal.pdf" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.1007/s00778-021-00726-w" target="_blank">DOI:10.1007/s00778-021-00726-w</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="Schrder2022">
  
    <span class="title">Structure-based knowledge acquisition from electronic lab notebooks for research data provenance documentation</span>
    <span class="author">
      
        
          
            
              
                Max Schröder,
              
            
          
        
      
        
          
            
              
                Susanne Staehlke,
              
            
          
        
      
        
          
            
              
                Paul Groth,
              
            
          
        
      
        
          
            
              
                J. Barbara Nebe,
              
            
          
        
      
        
          
            
              
                Sascha Spors,
              
            
          
        
      
        
          
            
              
                and Frank Krüger
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>Journal of Biomedical Semantics</em>
    
    
      2022
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="https://doi.org/10.1186/s13326-021-00257-x" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.1186/s13326-021-00257-x" target="_blank">DOI:10.1186/s13326-021-00257-x</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="DBLP:conf/cidr/SchelterGGSK022a">
  
    <span class="title">Screening Native Machine Learning Pipelines with ArgusEyes</span>
    <span class="author">
      
        
          
            
              
                Sebastian Schelter,
              
            
          
        
      
        
          
            
              
                Stefan Grafberger,
              
            
          
        
      
        
          
            
              
                Shubha Guha,
              
            
          
        
      
        
          
            
              
                Olivier Sprangers,
              
            
          
        
      
        
          
            
              
                Bojan Karlas,
              
            
          
        
      
        
          
            
              
                and Ce Zhang
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In 12th Conference on Innovative Data Systems Research, CIDR 2022,
 Chaminade, CA, USA, January 9-12, 2022</em>
    
    
      2022
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="https://www.cidrdb.org/cidr2022/papers/a1-schelter.pdf" target="_blank">Link</a>]
  
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="DBLP:conf/esws/2022">
  
    <span class="title">The Semantic Web - 19th International Conference, ESWC 2022, Hersonissos,
 Crete, Greece, May 29 - June 2, 2022, Proceedings</span>
    <span class="author">
      
    </span>

    <span class="periodical">
    
    
      2022
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="https://2022.eswc-conferences.org/accepted-papers/" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.1007/978-3-031-06981-9" target="_blank">DOI:10.1007/978-3-031-06981-9</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="DBLP:conf/semweb/CarrieroGP22">
  
    <span class="title">Towards improving Wikidata reuse with emerging patterns</span>
    <span class="author">
      
        
          
            
              
                Valentina Anita Carriero,
              
            
          
        
      
        
          
            
              
                Paul Groth,
              
            
          
        
      
        
          
            
              
                and Valentina Presutti
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Proceedings of the 3rd Wikidata Workshop 2022 co-located with the
 21st International Semantic Web Conference (ISWC2022), Virtual Event,
 Hanghzou, China, October 2022</em>
    
    
      2022
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="http://ceur-ws.org/Vol-3262/paper2.pdf" target="_blank">Link</a>]
  
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="DBLP:conf/semweb/2021semtab">
  
    <span class="title">Proceedings of the Semantic Web Challenge on Tabular Data to Knowledge
 Graph Matching co-located with the 20th International Semantic Web
 Conference (ISWC 2021), Virtual conference, October 27, 2021</span>
    <span class="author">
      
        
          
            
              
                Ernesto Jiménez-Ruiz,
              
            
          
        
      
        
          
            
              
                Vasilis Efthymiou,
              
            
          
        
      
        
          
            
              
                Jiaoyan Chen,
              
            
          
        
      
        
          
            
              
                Vincenzo Cutrona,
              
            
          
        
      
        
          
            
              
                Oktie Hassanzadeh,
              
            
          
        
      
        
          
            
              
                Juan Sequeda,
              
            
          
        
      
        
          
            
              
                Kavitha Srinivas,
              
            
          
        
      
        
          
            
              
                Nora Abdelmageed,
              
            
          
        
      
        
          
            
              
                Madelon Hulsebos,
              
            
          
        
      
        
          
            
              
                Daniela Oliveira,
              
            
          
        
      
        
          
            
              
                and Catia Pesquita
              
            
          
        
      
    </span>

    <span class="periodical">
    
    
      2022
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="http://ceur-ws.org/Vol-3103" target="_blank">Link</a>]
  
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="huang2022adarl">
  
    <span class="title">AdaRL: What, Where, and How to Adapt in Transfer Reinforcement Learning</span>
    <span class="author">
      
        
          
            
              
                Biwei Huang,
              
            
          
        
      
        
          
            
              
                Fan Feng,
              
            
          
        
      
        
          
            
              
                Chaochao Lu,
              
            
          
        
      
        
          
            
              
                Sara Magliacane,
              
            
          
        
      
        
          
            
              
                and Kun Zhang
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In International Conference on Learning Representations</em>
    
    
      2022
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="https://openreview.net/forum?id=8H5bpVwvt5" target="_blank">Link</a>]
  
  
  
  
  
  
  
  
    [<a href="https://openreview.net/group?id=ICLR.cc/2022/Conference#spotlight-submissions%20" target="_blank"> <img class="emoji" title=":tada:" alt=":tada:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f389.png" height="20" width="20"> Spotlight Presentation </a>]
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="vos2022towards">
  
    <span class="title">Towards Parameter-Efficient Automation of Data Wrangling Tasks with Prefix-Tuning</span>
    <span class="author">
      
        
          
            
              
                David Vos,
              
            
          
        
      
        
          
            
              
                Till Döhmen,
              
            
          
        
      
        
          
            
              
                and Sebastian Schelter
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In NeurIPS 2022 First Table Representation Workshop</em>
    
    
      2022
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="https://openreview.net/forum?id=8kyYJs2YkFH" target="_blank">Link</a>]
  
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="gitschemas">
  
    <span class="title">GitSchemas: A Dataset for Automating Relational Data Preparation Tasks</span>
    <span class="author">
      
        
          
            
              
                Till Döhmen,
              
            
          
        
      
        
          
            
              
                Madelon Hulsebos,
              
            
          
        
      
        
          
            
              
                Christian Beecks,
              
            
          
        
      
        
          
            
              
                and Sebastian Schelter
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In 2022 IEEE 38th International Conference on Data Engineering Workshops (ICDEW)</em>
    
    
      2022
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="https://madelonhulsebos.github.io/assets/GitSchemas.pdf" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.1109/ICDEW55742.2022.00016" target="_blank">DOI:10.1109/ICDEW55742.2022.00016</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="DBLP:conf/cidr/HulsebosGGDGD22">
  
    <span class="title">Making Table Understanding Work in Practice</span>
    <span class="author">
      
        
          
            
              
                Madelon Hulsebos,
              
            
          
        
      
        
          
            
              
                Sneha Gathani,
              
            
          
        
      
        
          
            
              
                James Gale,
              
            
          
        
      
        
          
            
              
                Isil Dillig,
              
            
          
        
      
        
          
            
              
                Paul Groth,
              
            
          
        
      
        
          
            
              
                and  Demiralp
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In 12th Conference on Innovative Data Systems Research, CIDR 2022,
 Chaminade, CA, USA, January 9-12, 2022</em>
    
    
      2022
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="https://www.cidrdb.org/cidr2022/papers/a48-hulsebos.pdf" target="_blank">Link</a>]
  
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
</ol>

<h3 class="year">2021</h3>
<ol class="bibliography">
<li>

<div id="Nevin2021">
  
    <span class="title">The non-linear impact of data handling on network diffusion models</span>
    <span class="author">
      
        
          
            
              
                James Nevin,
              
            
          
        
      
        
          
            
              
                Michael Lees,
              
            
          
        
      
        
          
            
              
                and Paul Groth
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>Patterns</em>
    
    
      2021
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="https://doi.org/10.1016/j.patter.2021.100397" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.1016/j.patter.2021.100397" target="_blank">DOI:10.1016/j.patter.2021.100397</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="boef_graphpope:_2021">
  
    <span class="title">GraphPOPE: Retaining Structural Graph Information Using Position-aware Node
Embeddings</span>
    <span class="author">
      
        
          
            
              
                Jeroen Den Boef,
              
            
          
        
      
        
          
            
              
                Joran Cornelisse,
              
            
          
        
      
        
          
            
              
                and Paul Groth
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Proceedings of the Workshop on Deep Learning for Knowledge Graphs (DL4KG 2021)</em>
    
    
      2021
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="http://ceur-ws.org/Vol-3034/#paper3" target="_blank">Link</a>]
  
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="szarkowska_quality_2021">
  
    <span class="title">Quality Assessment of Knowledge Graph Hierarchies using KG-BERT</span>
    <span class="author">
      
        
          
            
              
                Kinga Szarkowska,
              
            
          
        
      
        
          
            
              
                Veronique Moore,
              
            
          
        
      
        
          
            
              
                Pierre-Yves Vandenbussche,
              
            
          
        
      
        
          
            
              
                and Paul Groth
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Proceedings of the Workshop on Deep Learning for Knowledge Graphs (DL4KG 2021)</em>
    
    
      2021
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="http://ceur-ws.org/Vol-3034/#paper1" target="_blank">Link</a>]
  
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="Lamprecht2021">
  
    <span class="title">Perspectives on automated composition of workflows in the life sciences</span>
    <span class="author">
      
        
          
            
              
                Anna-Lena Lamprecht,
              
            
          
        
      
        
          
            
              
                Magnus Palmblad,
              
            
          
        
      
        
          
            
              
                Jon Ison,
              
            
          
        
      
        
          
            
              
                Veit Schwämmle,
              
            
          
        
      
        
          
            
              
                Mohammad Sadnan Al Manir,
              
            
          
        
      
        
          
            
              
                Ilkay Altintas,
              
            
          
        
      
        
          
            
              
                Christopher J. O. Baker,
              
            
          
        
      
        
          
            
              
                Ammar Ben Hadj Amor,
              
            
          
        
      
        
          
            
              
                Salvador Capella-Gutierrez,
              
            
          
        
      
        
          
            
              
                Paulos Charonyktakis,
              
            
          
        
      
        
          
            
              
                Michael R. Crusoe,
              
            
          
        
      
        
          
            
              
                Yolanda Gil,
              
            
          
        
      
        
          
            
              
                Carole Goble,
              
            
          
        
      
        
          
            
              
                Timothy J. Griffin,
              
            
          
        
      
        
          
            
              
                Paul Groth,
              
            
          
        
      
        
          
            
              
                Hans Ienasescu,
              
            
          
        
      
        
          
            
              
                Pratik Jagtap,
              
            
          
        
      
        
          
            
              
                Matúš Kalaš,
              
            
          
        
      
        
          
            
              
                Vedran Kasalica,
              
            
          
        
      
        
          
            
              
                Alireza Khanteymoori,
              
            
          
        
      
        
          
            
              
                Tobias Kuhn,
              
            
          
        
      
        
          
            
              
                Hailiang Mei,
              
            
          
        
      
        
          
            
              
                Hervé Ménager,
              
            
          
        
      
        
          
            
              
                Steffen Möller,
              
            
          
        
      
        
          
            
              
                Robin A. Richardson,
              
            
          
        
      
        
          
            
              
                Vincent Robert,
              
            
          
        
      
        
          
            
              
                Stian Soiland-Reyes,
              
            
          
        
      
        
          
            
              
                Robert Stevens,
              
            
          
        
      
        
          
            
              
                Szoke Szaniszlo,
              
            
          
        
      
        
          
            
              
                Suzan Verberne,
              
            
          
        
      
        
          
            
              
                Aswin Verhoeven,
              
            
          
        
      
        
          
            
              
                and Katherine Wolstencroft
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>F1000Research</em>
    
    
      2021
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="https://doi.org/10.12688/f1000research.54159.1" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.12688/f1000research.54159.1" target="_blank">DOI:10.12688/f1000research.54159.1</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="harper-etal-2021-semeval">
  
    <span class="title">SemEval-2021 Task 8: MeasEval – Extracting Counts and Measurements and their Related Contexts</span>
    <span class="author">
      
        
          
            
              
                Corey Harper,
              
            
          
        
      
        
          
            
              
                Jessica Cox,
              
            
          
        
      
        
          
            
              
                Curt Kohler,
              
            
          
        
      
        
          
            
              
                Antony Scerri,
              
            
          
        
      
        
          
            
              
                Ron Daniel Jr.,
              
            
          
        
      
        
          
            
              
                and Paul Groth
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Proceedings of the 15th International Workshop on Semantic Evaluation (SemEval-2021)</em>
    
    
      2021
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
  
    [<a href="https://aclanthology.org/2021.semeval-1.38" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.18653/v1/2021.semeval-1.38" target="_blank">DOI:10.18653/v1/2021.semeval-1.38</a>]
  
  
  
  
  
  
  
    [<a href="https://semeval.github.io/SemEval2021/awards%20" target="_blank"> <img class="emoji" title=":tada:" alt=":tada:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f389.png" height="20" width="20"> SemEval 2021 Best Task Paper </a>]
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>We describe MeasEval, a SemEval task of extracting counts, measurements, and related context from scientific documents, which is of significant importance to the creation of Knowledge Graphs that distill information from the scientific literature. This is a new task in 2021, for which over 75 submissions from 25 participants were received. We expect the data developed for this task and the findings reported to be valuable to the scientific knowledge extraction, metrology, and automated knowledge base construction communities.</p>
  </span>
  
</div>
</li>
<li>

<div id="alam_further_2021">
  
    <span class="title">Further with Knowledge Graphs: Proceedings of the 17th International Conference on Semantic Systems, 6–9 September 2021, Amsterdam, The Netherlands</span>
    <span class="author">
      
    </span>

    <span class="periodical">
    
    
      2021
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="https://ebooks.iospress.nl/doi/10.3233/SSW53" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.3233/SSW53" target="_blank">DOI:10.3233/SSW53</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="10.1145/3446428">
  
    <span class="title">Reinforcement Learning–Based Collective Entity Alignment with Adaptive Features</span>
    <span class="author">
      
        
          
            
              
                Weixin Zeng,
              
            
          
        
      
        
          
            
              
                Xiang Zhao,
              
            
          
        
      
        
          
            
              
                Jiuyang Tang,
              
            
          
        
      
        
          
            
              
                Xuemin Lin,
              
            
          
        
      
        
          
            
              
                and Paul Groth
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>ACM Trans. Inf. Syst.</em>
    
    
      2021
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
  
    [<a href="https://doi.org/10.1145/3446428" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.1145/3446428" target="_blank">DOI:10.1145/3446428</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Entity alignment (EA) is the task of identifying the entities that refer to the same real-world object but are located in different knowledge graphs (KGs). For entities to be aligned, existing EA solutions treat them separately and generate alignment results as ranked lists of entities on the other side. Nevertheless, this decision-making paradigm fails to take into account the interdependence among entities. Although some recent efforts mitigate this issue by imposing the 1-to-1 constraint on the alignment process, they still cannot adequately model the underlying interdependence and the results tend to be sub-optimal.To fill in this gap, in this work, we delve into the dynamics of the decision-making process, and offer a reinforcement learning (RL)–based model to align entities collectively. Under the RL framework, we devise the coherence and exclusiveness constraints to characterize the interdependence and restrict collective alignment. Additionally, to generate more precise inputs to the RL framework, we employ representative features to capture different aspects of the similarity between entities in heterogeneous KGs, which are integrated by an adaptive feature fusion strategy. Our proposal is evaluated on both cross-lingual and mono-lingual EA benchmarks and compared against state-of-the-art solutions. The empirical results verify its effectiveness and superiority.</p>
  </span>
  
</div>
</li>
<li>

<div id="Kersbergen2021">
  
    <span class="title">Learnings from a Retail Recommendation System on Billions of Interactions at bol.com</span>
    <span class="author">
      
        
          
            
              
                B. Kersbergen,
              
            
          
        
      
        
          
            
              
                and S. Schelter
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In 2021 IEEE 37th International Conference on Data Engineering (ICDE)</em>
    
    
      2021
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="https://ssc.io/pdf/bol-reco.pdf" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.1109/ICDE51399.2021.00277" target="_blank">DOI:10.1109/ICDE51399.2021.00277</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="daza2021inductive">
  
    <span class="title">Inductive Entity Representations from Text via Link Prediction</span>
    <span class="author">
      
        
          
            
              
                Daniel Daza,
              
            
          
        
      
        
          
            
              
                Michael Cochez,
              
            
          
        
      
        
          
            
              
                and Paul Groth
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Proceedings of The Web Conference</em>
    
    
      2021
    
    </span>
  

  <span class="links">
  
  
    [<a href="http://arxiv.org/abs/2010.03496" target="_blank">arXiv</a>]
  
  
  
  
  
    [<a href="http://doi.org/10.1145/3442381.3450141" target="_blank">DOI:10.1145/3442381.3450141</a>]
  
  
  
  
  
    [<a href="https://github.com/dfdazac/blp" target="_blank">Code</a>]
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="schelterspecialissuf">
  
    <span class="title">Letter from the Special Issue Editor</span>
    <span class="author">
      
        
          
            Sebastian Schelter
          
        
      
    </span>

    <span class="periodical">
    
      <em>IEEE Data Engineering Bulletin (Special issue on Data validation for machine learning models and applications)</em>
    
    
      2021
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="http://sites.computer.org/debull/A21mar/p2.pdf" target="_blank">Link</a>]
  
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="arakelyan2021complex">
  
    <span class="title">Complex Query Answering with Neural Link Predictors</span>
    <span class="author">
      
        
          
            
              
                Erik Arakelyan,
              
            
          
        
      
        
          
            
              
                Daniel Daza,
              
            
          
        
      
        
          
            
              
                Pasquale Minervini,
              
            
          
        
      
        
          
            
              
                and Michael Cochez
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In International Conference on Learning Representations (ICLR)</em>
    
    
      2021
    
    </span>
  

  <span class="links">
  
  
    [<a href="http://arxiv.org/abs/2011.03459" target="_blank">arXiv</a>]
  
  
  
  
    [<a href="https://openreview.net/forum?id=Mos9F9kDwkz" target="_blank">Link</a>]
  
  
  
  
  
  
  
  
    [<a href="https://iclr-conf.medium.com/announcing-iclr-2021-outstanding-paper-awards-9ae0514734ab%20" target="_blank"> <img class="emoji" title=":tada:" alt=":tada:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f389.png" height="20" width="20"> Outstanding Paper Award ICLR 2021 </a>]
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="scheltertaming">
  
    <span class="title">Taming Technical Bias in Machine Learning Pipelines</span>
    <span class="author">
      
        
          
            
              
                Sebastian Schelter,
              
            
          
        
      
        
          
            
              
                and Julia Stoyanovich
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>IEEE Data Engineering Bulletin (Special Issue on Interdisciplinary Perspectives on Fairness and Artificial Intelligence Systems)</em>
    
    
      2021
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="http://sites.computer.org/debull/A20dec/p39.pdf" target="_blank">Link</a>]
  
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="KOESTEN2021102562">
  
    <span class="title">Talking datasets – Understanding data sensemaking behaviours</span>
    <span class="author">
      
        
          
            
              
                Laura Koesten,
              
            
          
        
      
        
          
            
              
                Kathleen Gregory,
              
            
          
        
      
        
          
            
              
                Paul Groth,
              
            
          
        
      
        
          
            
              
                and Elena Simperl
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>International Journal of Human-Computer Studies</em>
    
    
      2021
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
    [<a href="http://arxiv.org/abs/1911.09041" target="_blank">arXiv</a>]
  
  
  
  
    [<a href="http://www.sciencedirect.com/science/article/pii/S1071581920301646" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.1016/j.ijhcs.2020.102562" target="_blank">DOI:10.1016/j.ijhcs.2020.102562</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>The sharing and reuse of data are seen as critical to solving the most complex problems of today. Despite this potential, relatively little attention has been paid to a key step in data reuse: the behaviours involved in data-centric sensemaking. We aim to address this gap by presenting a mixed-methods study combining in-depth interviews, a think-aloud task and a screen recording analysis with 31 researchers from different disciplines as they summarised and interacted with both familiar and unfamiliar data. We use our findings to identify and detail common patterns of data-centric sensemaking across three clusters of activities that we present as a framework: inspecting data, engaging with content, and placing data within broader contexts. Additionally, we propose design recommendations for tools and documentation practices, which can be used to facilitate sensemaking and subsequent data reuse.</p>
  </span>
  
</div>
</li>
<li>

<div id="10.1145/3460210.3493573">
  
    <span class="title">The Challenges of Cross-Document Coreference Resolution for Email</span>
    <span class="author">
      
        
          
            
              
                Xue Li,
              
            
          
        
      
        
          
            
              
                Sara Magliacane,
              
            
          
        
      
        
          
            
              
                and Paul Groth
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Proceedings of the 11th on Knowledge Capture Conference</em>
    
    
      2021
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
  
    [<a href="https://doi.org/10.1145/3460210.3493573" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.1145/3460210.3493573" target="_blank">DOI:10.1145/3460210.3493573</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Long-form conversations such as email are an important source of information for knowledge capture. For tasks such as knowledge graph construction, conversational search, and entity linking, being able to resolve entities from across documents is important. Building on recent work on within document coreference resolution for email, we study for the first time a cross-document formulation of the problem. Our results show that the current state-of-the-art deep learning models for general cross-document coreference resolution are insufficient for email conversations. Our experiments show that the general task is challenging and, importantly for knowledge intensive tasks, coreference resolution models that only treat entity mentions perform worse. Based on these results, we outline the work needed to address this challenging task.</p>
  </span>
  
</div>
</li>
<li>

<div id="DBLP:conf/esws/ShroffVMG21">
  
    <span class="title">Supporting Ontology Maintenance with Contextual Word Embeddings and
 Maximum Mean Discrepancy</span>
    <span class="author">
      
        
          
            
              
                Natasha Shroff,
              
            
          
        
      
        
          
            
              
                Pierre-Yves Vandenbussche,
              
            
          
        
      
        
          
            
              
                Véronique Moore,
              
            
          
        
      
        
          
            
              
                and Paul Groth
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Joint Proceedings of the 2nd International Workshop on Deep Learning
 meets Ontologies and Natural Language Processing (DeepOntoNLP 2021)
               &amp; 6th International Workshop on Explainable Sentiment Mining
 and Emotion Detection (X-SENTIMENT 2021) co-located with co-located
 with 18th Extended Semantic Web Conference 2021, Hersonissos, Greece,
 June 6th - 7th, 2021 (moved online)</em>
    
    
      2021
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="http://ceur-ws.org/Vol-2918/paper2.pdf" target="_blank">Link</a>]
  
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="DBLP:conf/pkdd/2021mlsmkg">
  
    <span class="title">Proceedings of Machine Learning with Symbolic Methods and Knowledge Graphs co-located
 with European Conference on Machine Learning and Principles and Practice
 of Knowledge Discovery in Databases (ECML PKDD 2021), Virtual,
 September 17, 2021</span>
    <span class="author">
      
        
          
            
              
                Mehwish Alam,
              
            
          
        
      
        
          
            
              
                Mehdi Ali,
              
            
          
        
      
        
          
            
              
                Paul Groth,
              
            
          
        
      
        
          
            
              
                Pascal Hitzler,
              
            
          
        
      
        
          
            
              
                Jens Lehmann,
              
            
          
        
      
        
          
            
              
                Heiko Paulheim,
              
            
          
        
      
        
          
            
              
                Achim Rettinger,
              
            
          
        
      
        
          
            
              
                Harald Sack,
              
            
          
        
      
        
          
            
              
                Afshin Sadeghi,
              
            
          
        
      
        
          
            
              
                and Volker Tresp
              
            
          
        
      
    </span>

    <span class="periodical">
    
    
      2021
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="http://ceur-ws.org/Vol-2997" target="_blank">Link</a>]
  
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="10.1145/3447928.3456653">
  
    <span class="title">Verifiably Safe Exploration for End-to-End Reinforcement Learning</span>
    <span class="author">
      
        
          
            
              
                Nathan Hunt,
              
            
          
        
      
        
          
            
              
                Nathan Fulton,
              
            
          
        
      
        
          
            
              
                Sara Magliacane,
              
            
          
        
      
        
          
            
              
                Trong Nghia Hoang,
              
            
          
        
      
        
          
            
              
                Subhro Das,
              
            
          
        
      
        
          
            
              
                and Armando Solar-Lezama
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Proceedings of the 24th International Conference on Hybrid Systems: Computation and Control</em>
    
    
      2021
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
  
    [<a href="https://doi.org/10.1145/3447928.3456653" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.1145/3447928.3456653" target="_blank">DOI:10.1145/3447928.3456653</a>]
  
  
  
  
  
  
  
    [<a href="https://hscc.acm.org/2021/awards/%20" target="_blank"> <img class="emoji" title=":tada:" alt=":tada:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f389.png" height="20" width="20"> Best Paper Award ACM HSCC 2021 </a>]
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Deploying deep reinforcement learning in safety-critical settings requires developing algorithms that obey hard constraints during exploration. This paper contributes a first approach toward enforcing formal safety constraints on end-to-end policies with visual inputs. Our approach draws on recent advances in object detection and automated reasoning for hybrid dynamical systems. The approach is evaluated on a novel benchmark that emphasizes the challenge of safely exploring in the presence of hard constraints. Our benchmark draws from several proposed problem sets for safe learning and includes problems that emphasize challenges such as reward signals that are not aligned with safety constraints. On each of these benchmark problems, our algorithm completely avoids unsafe behavior while remaining competitive at optimizing for as much reward as is safe. We characterize safety constraints in terms of a refinement relation on Markov decision processes - rather than directly constraining the reinforcement learning algorithm so that it only takes safe actions, we instead refine the environment so that only safe actions are defined in the environment’s transition structure. This has pragmatic system design benefits and, more importantly, provides a clean conceptual setting in which we are able to prove important safety and efficiency properties. These allow us to transform the constrained optimization problem of acting safely in the original environment into an unconstrained optimization in a refined environment.</p>
  </span>
  
</div>
</li>
<li>

<div id="10.1145/3442442.3453701">
  
    <span class="title">Summary of Tutorials at The Web Conference 2021</span>
    <span class="author">
      
        
          
            
              
                Robert West,
              
            
          
        
      
        
          
            
              
                Smriti Bhagat,
              
            
          
        
      
        
          
            
              
                Paul Groth,
              
            
          
        
      
        
          
            
              
                Marinka Zitnik,
              
            
          
        
      
        
          
            
              
                Francisco M. Couto,
              
            
          
        
      
        
          
            
              
                Pasquale Lisena,
              
            
          
        
      
        
          
            
              
                Albert Meroño-Peñuela,
              
            
          
        
      
        
          
            
              
                Xiangyu Zhao,
              
            
          
        
      
        
          
            
              
                Wenqi Fan,
              
            
          
        
      
        
          
            
              
                Dawei Yin,
              
            
          
        
      
        
          
            
              
                Jiliang Tang,
              
            
          
        
      
        
          
            
              
                Linjun Shou,
              
            
          
        
      
        
          
            
              
                Ming Gong,
              
            
          
        
      
        
          
            
              
                Jian Pei,
              
            
          
        
      
        
          
            
              
                Xiubo Geng,
              
            
          
        
      
        
          
            
              
                Xingjie Zhou,
              
            
          
        
      
        
          
            
              
                Daxin Jiang,
              
            
          
        
      
        
          
            
              
                Benjamin Ricaud,
              
            
          
        
      
        
          
            
              
                Nicolas Aspert,
              
            
          
        
      
        
          
            
              
                Volodymyr Miz,
              
            
          
        
      
        
          
            
              
                Jennifer Dy,
              
            
          
        
      
        
          
            
              
                Stratis Ioannidis,
              
            
          
        
      
        
          
            
              
                undefinedlkay Yıldız,
              
            
          
        
      
        
          
            
              
                Rezvaneh Rezapour,
              
            
          
        
      
        
          
            
              
                Samin Aref,
              
            
          
        
      
        
          
            
              
                Ly Dinh,
              
            
          
        
      
        
          
            
              
                Jana Diesner,
              
            
          
        
      
        
          
            
              
                Alexey Drutsa,
              
            
          
        
      
        
          
            
              
                Dmitry Ustalov,
              
            
          
        
      
        
          
            
              
                Nikita Popov,
              
            
          
        
      
        
          
            
              
                Daria Baidakova,
              
            
          
        
      
        
          
            
              
                Shubhanshu Mishra,
              
            
          
        
      
        
          
            
              
                Arjun Gopalan,
              
            
          
        
      
        
          
            
              
                Da-Cheng Juan,
              
            
          
        
      
        
          
            
              
                Cesar Ilharco Magalhaes,
              
            
          
        
      
        
          
            
              
                Chun-Sung Ferng,
              
            
          
        
      
        
          
            
              
                Allan Heydon,
              
            
          
        
      
        
          
            
              
                Chun-Ta Lu,
              
            
          
        
      
        
          
            
              
                Philip Pham,
              
            
          
        
      
        
          
            
              
                George Yu,
              
            
          
        
      
        
          
            
              
                Yicheng Fan,
              
            
          
        
      
        
          
            
              
                Yueqi Wang,
              
            
          
        
      
        
          
            
              
                Florian Laurent,
              
            
          
        
      
        
          
            
              
                Yanick Schraner,
              
            
          
        
      
        
          
            
              
                Christian Scheller,
              
            
          
        
      
        
          
            
              
                Sharada Mohanty,
              
            
          
        
      
        
          
            
              
                Jiawei Chen,
              
            
          
        
      
        
          
            
              
                Xiang Wang,
              
            
          
        
      
        
          
            
              
                Fuli Feng,
              
            
          
        
      
        
          
            
              
                Xiangnan He,
              
            
          
        
      
        
          
            
              
                Irene Teinemaa,
              
            
          
        
      
        
          
            
              
                Javier Albert,
              
            
          
        
      
        
          
            
              
                Dmitri Goldenberg,
              
            
          
        
      
        
          
            
              
                Flavian Vasile,
              
            
          
        
      
        
          
            
              
                David Rohde,
              
            
          
        
      
        
          
            
              
                Olivier Jeunen,
              
            
          
        
      
        
          
            
              
                Amine Benhalloum,
              
            
          
        
      
        
          
            
              
                Otmane Sakhi,
              
            
          
        
      
        
          
            
              
                Yu Rong,
              
            
          
        
      
        
          
            
              
                Wenbing Huang,
              
            
          
        
      
        
          
            
              
                Tingyang Xu,
              
            
          
        
      
        
          
            
              
                Yatao Bian,
              
            
          
        
      
        
          
            
              
                Hong Cheng,
              
            
          
        
      
        
          
            
              
                Fuchun Sun,
              
            
          
        
      
        
          
            
              
                Junzhou Huang,
              
            
          
        
      
        
          
            
              
                Shobeir Fakhraei,
              
            
          
        
      
        
          
            
              
                Christos Faloutsos,
              
            
          
        
      
        
          
            
              
                Onur Çelebi,
              
            
          
        
      
        
          
            
              
                Martin Müller,
              
            
          
        
      
        
          
            
              
                Manuel Schneider,
              
            
          
        
      
        
          
            
              
                Olesia Altunina,
              
            
          
        
      
        
          
            
              
                Wolfram Wingerath,
              
            
          
        
      
        
          
            
              
                Benjamin Wollmer,
              
            
          
        
      
        
          
            
              
                Felix Gessert,
              
            
          
        
      
        
          
            
              
                Stephan Succo,
              
            
          
        
      
        
          
            
              
                Norbert Ritter,
              
            
          
        
      
        
          
            
              
                Evann Courdier,
              
            
          
        
      
        
          
            
              
                Tudor Mihai Avram,
              
            
          
        
      
        
          
            
              
                Dragan Cvetinovic,
              
            
          
        
      
        
          
            
              
                Levan Tsinadze,
              
            
          
        
      
        
          
            
              
                Johny Jose,
              
            
          
        
      
        
          
            
              
                Rose Howell,
              
            
          
        
      
        
          
            
              
                Mario Koenig,
              
            
          
        
      
        
          
            
              
                Michaël Defferrard,
              
            
          
        
      
        
          
            
              
                Krishnaram Kenthapadi,
              
            
          
        
      
        
          
            
              
                Ben Packer,
              
            
          
        
      
        
          
            
              
                Mehrnoosh Sameki,
              
            
          
        
      
        
          
            
              
                and Nashlie Sephus
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Companion Proceedings of the Web Conference 2021</em>
    
    
      2021
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
  
    [<a href="https://doi.org/10.1145/3442442.3453701" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.1145/3442442.3453701" target="_blank">DOI:10.1145/3442442.3453701</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>This report summarizes the 23 tutorials hosted at The Web Conference 2021: nine lecture-style tutorials and 14 hands-on tutorials.</p>
  </span>
  
</div>
</li>
<li>

<div id="10.1145/3448016.3457239">
  
    <span class="title">HedgeCut: Maintaining Randomised Trees for Low-Latency Machine Unlearning</span>
    <span class="author">
      
        
          
            
              
                Sebastian Schelter,
              
            
          
        
      
        
          
            
              
                Stefan Grafberger,
              
            
          
        
      
        
          
            
              
                and Ted Dunning
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Proceedings of the 2021 International Conference on Management of Data</em>
    
    
      2021
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
  
    [<a href="https://doi.org/10.1145/3448016.3457239" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.1145/3448016.3457239" target="_blank">DOI:10.1145/3448016.3457239</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Software systems that learn from user data with machine learning (ML) have become ubiquitous over the last years. Recent law such as the "General Data Protection Regulation" (GDPR) requires organisations that process personal data to delete user data upon request (enacting the "right to be forgotten"). However, this regulation does not only require the deletion of user data from databases, but also applies to ML models that have been learned from the stored data. We therefore argue that ML applications should offer users to unlearn their data from trained models in a timely manner. We explore how fast this unlearning can be done under the constraints imposed by real world deployments, and introduce the problem of low-latency machine unlearning: maintaining a deployed ML model in-place under the removal of a small fraction of training samples without retraining.We propose HedgeCut, a classification model based on an ensemble of randomised decision trees, which is designed to answer unlearning requests with low latency. We detail how to efficiently implement HedgeCut with vectorised operators for decision tree learning. We conduct an experimental evaluation on five privacy-sensitive datasets, where we find that HedgeCut can unlearn training samples with a latency of around 100 microseconds and answers up to 36,000 prediction requests per second, while providing a training time and predictive accuracy similar to widely used implementations of tree-based ML models such as Random Forests.</p>
  </span>
  
</div>
</li>
<li>

<div id="10.1145/3448016.3452759">
  
    <span class="title">MLINSPECT: A Data Distribution Debugger for Machine Learning Pipelines</span>
    <span class="author">
      
        
          
            
              
                Stefan Grafberger,
              
            
          
        
      
        
          
            
              
                Shubha Guha,
              
            
          
        
      
        
          
            
              
                Julia Stoyanovich,
              
            
          
        
      
        
          
            
              
                and Sebastian Schelter
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Proceedings of the 2021 International Conference on Management of Data</em>
    
    
      2021
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
  
    [<a href="https://doi.org/10.1145/3448016.3452759" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.1145/3448016.3452759" target="_blank">DOI:10.1145/3448016.3452759</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Machine Learning (ML) is increasingly used to automate impactful decisions, and the risks arising from this wide-spread use are garnering attention from policymakers, scientists, and the media. ML applications are often very brittle with respect to their input data, which leads to concerns about their reliability, accountability, and fairness. While bias detection cannot be fully automated, computational tools can help pinpoint particular types of data issues.We recently proposed mlinspect, a library that enables lightweight lineage-based inspection of ML preprocessing pipelines. In this demonstration, we show how mlinspect can be used to detect data distribution bugs in a representative pipeline. In contrast to existing work, mlinspect operates on declarative abstractions of popular data science libraries like estimator/transformer pipelines, can handle both relational and matrix data, and does not require manual code instrumentation. The library is publicly available at https://github.com/stefan-grafberger/mlinspect.</p>
  </span>
  
</div>
</li>
<li>

<div id="DBLP:conf/edbt/RedyukKMS21">
  
    <span class="title">Automating Data Quality Validation for Dynamic Data Ingestion</span>
    <span class="author">
      
        
          
            
              
                Sergey Redyuk,
              
            
          
        
      
        
          
            
              
                Zoi Kaoudi,
              
            
          
        
      
        
          
            
              
                Volker Markl,
              
            
          
        
      
        
          
            
              
                and Sebastian Schelter
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Proceedings of the 24th International Conference on Extending Database
 Technology, EDBT 2021, Nicosia, Cyprus, March 23 - 26, 2021</em>
    
    
      2021
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="https://doi.org/10.5441/002/edbt.2021.07" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.5441/002/edbt.2021.07" target="_blank">DOI:10.5441/002/edbt.2021.07</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="DBLP:conf/edbt/SchelterRB21">
  
    <span class="title">JENGA - A Framework to Study the Impact of Data Errors on the
 Predictions of Machine Learning Models</span>
    <span class="author">
      
        
          
            
              
                Sebastian Schelter,
              
            
          
        
      
        
          
            
              
                Tammo Rukat,
              
            
          
        
      
        
          
            
              
                and Felix Biessmann
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Proceedings of the 24th International Conference on Extending Database
 Technology, EDBT 2021, Nicosia, Cyprus, March 23 - 26, 2021</em>
    
    
      2021
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="https://doi.org/10.5441/002/edbt.2021.63" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.5441/002/edbt.2021.63" target="_blank">DOI:10.5441/002/edbt.2021.63</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="DBLP:conf/cidr/GrafbergerSS21">
  
    <span class="title">Lightweight Inspection of Data Preprocessing in Native Machine Learning
 Pipelines</span>
    <span class="author">
      
        
          
            
              
                Stefan Grafberger,
              
            
          
        
      
        
          
            
              
                Julia Stoyanovich,
              
            
          
        
      
        
          
            
              
                and Sebastian Schelter
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In 11th Conference on Innovative Data Systems Research, CIDR 2021,
 Virtual Event, January 11-15, 2021, Online Proceedings</em>
    
    
      2021
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="http://cidrdb.org/cidr2021/papers/cidr2021_paper27.pdf" target="_blank">Link</a>]
  
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
</ol>

<h3 class="year">2020</h3>
<ol class="bibliography">
<li>

<div id="brate-etal-2020-towards">
  
    <span class="title">Towards Olfactory Information Extraction from Text: A Case Study on Detecting Smell Experiences in Novels</span>
    <span class="author">
      
        
          
            
              
                Ryan Brate,
              
            
          
        
      
        
          
            
              
                Paul Groth,
              
            
          
        
      
        
          
            
              
                and Marieke Erp
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Proceedings of the The 4th Joint SIGHUM Workshop on Computational Linguistics for Cultural Heritage, Social Sciences, Humanities and Literature</em>
    
    
      2020
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
  
    [<a href="https://www.aclweb.org/anthology/2020.latechclfl-1.18" target="_blank">Link</a>]
  
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Environmental factors determine the smells we perceive, but societal factors factors shape the importance, sentiment and biases we give to them. Descriptions of smells in text, or as we call them ‘smell experiences’, offer a window into these factors, but they must first be identified. To the best of our knowledge, no tool exists to extract references to smell experiences from text. In this paper, we present two variations on a semi-supervised approach to identify smell experiences in English literature. The combined set of patterns from both implementations offer significantly better performance than a keyword-based baseline.</p>
  </span>
  
</div>
</li>
<li>

<div id="Koesten2020">
  
    <span class="title">Dataset Reuse: Toward Translating Principles to Practice</span>
    <span class="author">
      
        
          
            
              
                Laura Koesten,
              
            
          
        
      
        
          
            
              
                Pavlos Vougiouklis,
              
            
          
        
      
        
          
            
              
                Elena Simperl,
              
            
          
        
      
        
          
            
              
                and Paul Groth
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>Patterns</em>
    
    
      2020
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="https://doi.org/10.1016/j.patter.2020.100136" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.1016/j.patter.2020.100136" target="_blank">DOI:10.1016/j.patter.2020.100136</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="berger-etal-2020-effective">
  
    <span class="title">Effective distributed representations for academic expert search</span>
    <span class="author">
      
        
          
            
              
                Mark Berger,
              
            
          
        
      
        
          
            
              
                Jakub Zavrel,
              
            
          
        
      
        
          
            
              
                and Paul Groth
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Proceedings of the First Workshop on Scholarly Document Processing at EMNLP</em>
    
    
      2020
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
  
    [<a href="https://www.aclweb.org/anthology/2020.sdp-1.7" target="_blank">Link</a>]
  
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Expert search aims to find and rank experts based on a user’s query. In academia, retrieving experts is an efficient way to navigate through a large amount of academic knowledge. Here, we study how different distributed representations of academic papers (i.e. embeddings) impact academic expert retrieval. We use the Microsoft Academic Graph dataset and experiment with different configurations of a document-centric voting model for retrieval. In particular, we explore the impact of the use of contextualized embeddings on search performance. We also present results for paper embeddings that incorporate citation information through retrofitting. Additionally, experiments are conducted using different techniques for assigning author weights based on author order. We observe that using contextual embeddings produced by a transformer model trained for sentence similarity tasks produces the most effective paper representations for document-centric expert retrieval. However, retrofitting the paper embeddings and using elaborate author contribution weighting strategies did not improve retrieval performance.</p>
  </span>
  
</div>
</li>
<li>

<div id="Chapman2019">
  
    <span class="title">Dataset search: a survey</span>
    <span class="author">
      
        
          
            
              
                Adriane Chapman,
              
            
          
        
      
        
          
            
              
                Elena Simperl,
              
            
          
        
      
        
          
            
              
                Laura Koesten,
              
            
          
        
      
        
          
            
              
                George Konstantinidis,
              
            
          
        
      
        
          
            
              
                Luis-Daniel Ibáñez,
              
            
          
        
      
        
          
            
              
                Emilia Kacprzak,
              
            
          
        
      
        
          
            
              
                and Paul Groth
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>The VLDB Journal</em>
    
    
      2020
    
    </span>
  

  <span class="links">
  
  
    [<a href="http://arxiv.org/abs/1901.00735" target="_blank">arXiv</a>]
  
  
  
  
    [<a href="https://doi.org/10.1007/s00778-019-00564-x" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.1007/s00778-019-00564-x" target="_blank">DOI:10.1007/s00778-019-00564-x</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="GrothDumontier2020">
  
    <span class="title">Introduction – FAIR data, systems and analysis</span>
    <span class="author">
      
        
          
            
              
                Paul Groth,
              
            
          
        
      
        
          
            
              
                and Michel Dumontier
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>Data Science</em>
    
    
      2020
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="http://doi.org/10.3233/DS-200029" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.3233/DS-200029" target="_blank">DOI:10.3233/DS-200029</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="yang_2020">
  
    <span class="title">Fairness-Aware Instrumentation of Preprocessing Pipelines for Machine
Learning</span>
    <span class="author">
      
        
          
            
              
                Ke Yang,
              
            
          
        
      
        
          
            
              
                Biao Huang,
              
            
          
        
      
        
          
            
              
                Julia Stoyanovich,
              
            
          
        
      
        
          
            
              
                and Sebastian Schelter
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Workshop on Human-In-the-Loop Data Analytics (HILDA’20)</em>
    
    
      2020
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="https://ssc.io/pdf/hilda-fairdags.pdf" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.1145/3398730.3399194" target="_blank">DOI:10.1145/3398730.3399194</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="vanerp-groth:2020:LREC">
  
    <span class="title">Towards Entity Spaces</span>
    <span class="author">
      
        
          
            
              
                Marieke Erp,
              
            
          
        
      
        
          
            
              
                and Paul Groth
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Proceedings of The 12th Language Resources and Evaluation Conference</em>
    
    
      2020
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
  
    [<a href="https://www.aclweb.org/anthology/2020.lrec-1.261" target="_blank">Link</a>]
  
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Entities are a central element of knowledge bases and are important input to many knowledge-centric tasks including text analysis. For example, they allow us to find documents relevant to a specific entity irrespective of the underlying syntactic expression within a document. However, the entities that are commonly represented in knowledge bases are often a simplification of what is truly being referred to in text. For example, in a knowledge base, we may have an entity for Germany as a country but not for the more fuzzy concept of Germany that covers notions of German Population, German Drivers, and the German Government. Inspired by recent advances in contextual word embeddings, we introduce the concept of entity spaces - specific representations of a set of associated entities with near-identity. Thus, these entity spaces provide a handle to an amorphous grouping of entities. We developed a proof-of-concept for English showing how, through the introduction of entity spaces in the form of disambiguation pages, the recall of entity linking can be improved.</p>
  </span>
  
</div>
</li>
<li>

<div id="Gregory2020Lost">
  
    <span class="title">Lost or Found? Discovering Data Needed for Research </span>
    <span class="author">
      
        
          
            
              
                Kathleen Gregory,
              
            
          
        
      
        
          
            
              
                Paul Groth,
              
            
          
        
      
        
          
            
              
                Andrea Scharnhorst,
              
            
          
        
      
        
          
            
              
                and Sally Wyatt
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>Harvard Data Science Review</em>
    
    
      2020
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="https://hdsr.mitpress.mit.edu/pub/gw3r97ht" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.1162/99608f92.e38165eb" target="_blank">DOI:10.1162/99608f92.e38165eb</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="stamatogiannakis_pandacap_2020">
  
    <span class="title">PANDAcap: A Framework for Streamlining Collection of Full-System Traces</span>
    <span class="author">
      
        
          
            
              
                Manolis Stamatogiannakis,
              
            
          
        
      
        
          
            
              
                Herbert Bos,
              
            
          
        
      
        
          
            
              
                and Paul Groth
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In EuroSec</em>
    
    
      2020
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="https://download.vusec.net/papers/pandacap-eurosec20.pdf" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.1145/3380786.3391396" target="_blank">DOI:10.1145/3380786.3391396</a>]
  
  
  
  
  
    [<a href="https://github.com/vusec/pandacap" target="_blank">Code</a>]
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="Kastner2020">
  
    <span class="title">Estimating the imageability of words by mining visual characteristics from crawled image data</span>
    <span class="author">
      
        
          
            
              
                Marc A. Kastner,
              
            
          
        
      
        
          
            
              
                Ichiro Ide,
              
            
          
        
      
        
          
            
              
                Frank Nack,
              
            
          
        
      
        
          
            
              
                Yasutomo Kawanishi,
              
            
          
        
      
        
          
            
              
                Takatsugu Hirayama,
              
            
          
        
      
        
          
            
              
                Daisuke Deguchi,
              
            
          
        
      
        
          
            
              
                and Hiroshi Murase
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>Multimedia Tools and Applications</em>
    
    
      2020
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="https://doi.org/10.1007/s11042-019-08571-4" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.1007/s11042-019-08571-4" target="_blank">DOI:10.1007/s11042-019-08571-4</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="Groth2020">
  
    <span class="title">FAIR Data Reuse – the Path through Data Citation</span>
    <span class="author">
      
        
          
            
              
                Paul Groth,
              
            
          
        
      
        
          
            
              
                Helena Cousijn,
              
            
          
        
      
        
          
            
              
                Tim Clark,
              
            
          
        
      
        
          
            
              
                and Carole Goble
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>Data Intelligence</em>
    
    
      2020
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="https://doi.org/10.1162/dint_a_00030" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.1162/dint_a_00030" target="_blank">DOI:10.1162/dint_a_00030</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="daza2020message">
  
    <span class="title">Message Passing Query Embedding</span>
    <span class="author">
      
        
          
            
              
                Daniel Daza,
              
            
          
        
      
        
          
            
              
                and Michael Cochez
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In ICML Workshop - Graph Representation Learning and Beyond</em>
    
    
      2020
    
    </span>
  

  <span class="links">
  
  
    [<a href="http://arxiv.org/abs/2002.02406" target="_blank">arXiv</a>]
  
  
  
  
    [<a href="https://arxiv.org/abs/2002.02406" target="_blank">Link</a>]
  
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="https://doi.org/10.6084/m9.figshare.13010000.v2">
  
    <span class="title">The state of altmetrics: a tenth anniversary celebration</span>
    <span class="author">
      
        
          
            
              
                 Altmetric Engineering,
              
            
          
        
      
        
          
            
              
                Stacy Konkiel,
              
            
          
        
      
        
          
            
              
                Jason Priem,
              
            
          
        
      
        
          
            
              
                Euan Adie,
              
            
          
        
      
        
          
            
              
                Gemma Derrick,
              
            
          
        
      
        
          
            
              
                Fereshteh Didegah,
              
            
          
        
      
        
          
            
              
                Paul Groth,
              
            
          
        
      
        
          
            
              
                Cameron Neylon,
              
            
          
        
      
        
          
            
              
                 Shenmeng Xu,
              
            
          
        
      
        
          
            
              
                Zohreh Zahedi,
              
            
          
        
      
        
          
            
              
                Timothy Bowman,
              
            
          
        
      
        
          
            
              
                 Vanash M Patel,
              
            
          
        
      
        
          
            
              
                Robin Haunschild,
              
            
          
        
      
        
          
            
              
                Lutz Bornmann,
              
            
          
        
      
        
          
            
              
                Mike Taylor,
              
            
          
        
      
        
          
            
              
                Liesa Ross,
              
            
          
        
      
        
          
            
              
                Yin-Leng Theng,
              
            
          
        
      
        
          
            
              
                Saeed-Ul Hassan,
              
            
          
        
      
        
          
            
              
                and Naif R. Aljohani
              
            
          
        
      
    </span>

    <span class="periodical">
    
    
      2020
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="https://altmetric.figshare.com/articles/online_resource/The_State_of_Altmetrics_A_tenth_anniversary_celebration/13010000/2" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.6084/M9.FIGSHARE.13010000.V2" target="_blank">DOI:10.6084/M9.FIGSHARE.13010000.V2</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="10.1145/3340531.3414072">
  
    <span class="title">CSSA’20: Workshop on Combining Symbolic and Sub-Symbolic Methods and Their Applications</span>
    <span class="author">
      
        
          
            
              
                Mehwish Alam,
              
            
          
        
      
        
          
            
              
                Paul Groth,
              
            
          
        
      
        
          
            
              
                Pascal Hitzler,
              
            
          
        
      
        
          
            
              
                Heiko Paulheim,
              
            
          
        
      
        
          
            
              
                Harald Sack,
              
            
          
        
      
        
          
            
              
                and Volker Tresp
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management</em>
    
    
      2020
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
  
    [<a href="https://doi.org/10.1145/3340531.3414072" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.1145/3340531.3414072" target="_blank">DOI:10.1145/3340531.3414072</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>There has been a rapid growth in the use of symbolic representations along with their applications in many important tasks. Symbolic representations, in the form of Knowledge Graphs (KGs), constitute large networks of real-world entities and their relationships. On the other hand, sub-symbolic artificial intelligence has also become a mainstream area of research. This workshop brought together researchers to discuss and foster collaborations on the intersection of these two areas.</p>
  </span>
  
</div>
</li>
<li>

<div id="10.1007/978-3-030-62516-0_1">
  
    <span class="title">ICIDS2020 Panel: Building the Discipline of Interactive Digital Narratives</span>
    <span class="author">
      
        
          
            
              
                Mark Bernstein,
              
            
          
        
      
        
          
            
              
                Mirjam Palosaari Eladhari,
              
            
          
        
      
        
          
            
              
                Hartmut Koenitz,
              
            
          
        
      
        
          
            
              
                Sandy Louchart,
              
            
          
        
      
        
          
            
              
                Frank Nack,
              
            
          
        
      
        
          
            
              
                Chris Martens,
              
            
          
        
      
        
          
            
              
                Giulia Carla Rossi,
              
            
          
        
      
        
          
            
              
                Anne-Gwenn Bosser,
              
            
          
        
      
        
          
            
              
                and David E. Millard
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Interactive Storytelling</em>
    
    
      2020
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
  
  
    [<a href="http://doi.org/10.1007/978-3-030-62516-0_1" target="_blank">DOI:10.1007/978-3-030-62516-0_1</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Building our discipline has been an ongoing discussion since the early days of ICIDS. From earlier international joint efforts to integrate research from multiple fields of study to today’s endeavours by researchers to provide scholarly works of reference, the discussion on how to continue building Interactive Digital Narratives as a discipline with its own vocabulary, scope, evaluation and methods is far from over. This year, we have chosen to continue this discussion through a panel in order to explore what are the epistemological implications of the multiple disciplinary roots of our field, and what are the next steps we should take as a community.</p>
  </span>
  
</div>
</li>
<li>

<div id="schelterSigmodRecord2020">
  
    <span class="title">Technical Perspective: Query Optimization for Faster Deep CNN Explanations</span>
    <span class="author">
      
        
          
            Sebastian Schelter
          
        
      
    </span>

    <span class="periodical">
    
      <em>ACM SIGMOD Record</em>
    
    
      2020
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="https://sigmodrecord.org/?smd_process_download=1&amp;download_id=2686" target="_blank">Link</a>]
  
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="JMLR:v21:18-800">
  
    <span class="title">Apache Mahout: Machine Learning on Distributed Dataflow Systems</span>
    <span class="author">
      
        
          
            
              
                Robin Anil,
              
            
          
        
      
        
          
            
              
                Gokhan Capan,
              
            
          
        
      
        
          
            
              
                Isabel Drost-Fromm,
              
            
          
        
      
        
          
            
              
                Ted Dunning,
              
            
          
        
      
        
          
            
              
                Ellen Friedman,
              
            
          
        
      
        
          
            
              
                Trevor Grant,
              
            
          
        
      
        
          
            
              
                Shannon Quinn,
              
            
          
        
      
        
          
            
              
                Paritosh Ranjan,
              
            
          
        
      
        
          
            
              
                Sebastian Schelter,
              
            
          
        
      
        
          
            
              
                and Ã–zgÃ¼r YÄ±lmazel
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>Journal of Machine Learning Research</em>
    
    
      2020
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="http://jmlr.org/papers/v21/18-800.html" target="_blank">Link</a>]
  
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="DBLP:conf/i-semantics/2020">
  
    <span class="title">Semantic Systems. In the Era of Knowledge Graphs - 16th International
 Conference on Semantic Systems, SEMANTiCS 2020, Amsterdam, The Netherlands,
 September 7-10, 2020, Proceedings</span>
    <span class="author">
      
        
          
            
              
                Eva Blomqvist,
              
            
          
        
      
        
          
            
              
                Paul Groth,
              
            
          
        
      
        
          
            
              
                Victor Boer,
              
            
          
        
      
        
          
            
              
                Tassilo Pellegrini,
              
            
          
        
      
        
          
            
              
                Mehwish Alam,
              
            
          
        
      
        
          
            
              
                Tobias Käfer,
              
            
          
        
      
        
          
            
              
                Peter Kieseberg,
              
            
          
        
      
        
          
            
              
                Sabrina Kirrane,
              
            
          
        
      
        
          
            
              
                Albert Meroño-Peñuela,
              
            
          
        
      
        
          
            
              
                and Harshvardhan J. Pandit
              
            
          
        
      
    </span>

    <span class="periodical">
    
    
      2020
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="https://doi.org/10.1007/978-3-030-59833-4" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.1007/978-3-030-59833-4" target="_blank">DOI:10.1007/978-3-030-59833-4</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="selten2020">
  
    <span class="title">A longitudinal analysis of university rankings</span>
    <span class="author">
      
        
          
            
              
                Friso Selten,
              
            
          
        
      
        
          
            
              
                Cameron Neylon,
              
            
          
        
      
        
          
            
              
                Chun-Kai Huang,
              
            
          
        
      
        
          
            
              
                and Paul Groth
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>Quantitative Science Studies</em>
    
    
      2020
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="https://doi.org/10.1162/qss_a_00052%0A%0A" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.1162/qss_a_00052" target="_blank">DOI:10.1162/qss_a_00052</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
</ol>

<h3 class="year">2019</h3>
<ol class="bibliography">
<li>

<div id="10.1007/978-3-030-33894-7_9">
  
    <span class="title">How Relevant Is Your Choice? </span>
    <span class="author">
      
        
          
            
              
                Lobke Kolhoff,
              
            
          
        
      
        
          
            
              
                and Frank Nack
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In  ICIDS 2019. Lecture Notes in Computer Science, vol 11869</em>
    
    
      2019
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
  
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>With the release of the film Black Mirror: Bandersnatch Netflix entered the area of interactive streamed narratives. We performed a qualitative analysis with 169 Netflix subscribers that had watched the episode. The key findings show (1) participants are initially engaged because of curiosity and the novelty value, and desire to explore the narrative regardless of satisfaction, (2) perceived agency is limited due to arbitrary choices and the lack of meaningful consequences, (3) the overall experience is satisfactory but adaptions are desirable in future design to make full use of the potential of the format.</p>
  </span>
  
</div>
</li>
<li>

<div id="DBLP:conf/i-semantics/SymeonidouSG19">
  
    <span class="title">Transfer Learning for Biomedical Named Entity Recognition with BioBERT</span>
    <span class="author">
      
        
          
            
              
                Anthi Symeonidou,
              
            
          
        
      
        
          
            
              
                Viachaslau Sazonau,
              
            
          
        
      
        
          
            
              
                and Paul Groth
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Proceedings of the Posters and Demo Track of the 15th International
 Conference on Semantic Systems co-located with 15th International
 Conference on Semantic Systems (SEMANTiCS 2019), Karlsruhe, Germany,
 September 9th - to - 12th, 2019.</em>
    
    
      2019
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="http://ceur-ws.org/Vol-2451/paper-26.pdf" target="_blank">Link</a>]
  
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="doi:10.1177/0165551519837182">
  
    <span class="title">Understanding data search as a socio-technical practice</span>
    <span class="author">
      
        
          
            
              
                Kathleen M Gregory,
              
            
          
        
      
        
          
            
              
                Helena Cousijn,
              
            
          
        
      
        
          
            
              
                Paul Groth,
              
            
          
        
      
        
          
            
              
                Andrea Scharnhorst,
              
            
          
        
      
        
          
            
              
                and Sally Wyatt
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>Journal of Information Science</em>
    
    
      2019
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
  
    [<a href="https://doi.org/10.1177/0165551519837182" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.1177/0165551519837182" target="_blank">DOI:10.1177/0165551519837182</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p> Open research data are heralded as having the potential to increase effectiveness, productivity and reproducibility in science, but little is known about the actual practices involved in data search. The socio-technical problem of locating data for reuse is often reduced to the technological dimension of designing data search systems. We combine a bibliometric study of the current academic discourse around data search with interviews with data seekers. In this article, we explore how adopting a contextual, socio-technical perspective can help to understand user practices and behaviour and ultimately help to improve the design of data discovery systems. </p>
  </span>
  
</div>
</li>
<li>

<div id="doi:10.1002/asi.24165">
  
    <span class="title">Searching Data: A Review of Observational Data Retrieval Practices in Selected Disciplines</span>
    <span class="author">
      
        
          
            
              
                Kathleen Gregory,
              
            
          
        
      
        
          
            
              
                Paul Groth,
              
            
          
        
      
        
          
            
              
                Helena Cousijn,
              
            
          
        
      
        
          
            
              
                Andrea Scharnhorst,
              
            
          
        
      
        
          
            
              
                and Sally Wyatt
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>Journal of the Association for Information Science and Technology</em>
    
    
      2019
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
  
    [<a href="https://onlinelibrary.wiley.com/doi/abs/10.1002/asi.24165" target="_blank">Link</a>]
  
  
    [<a href="http://doi.org/10.1002/asi.24165" target="_blank">DOI:10.1002/asi.24165</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>A cross-disciplinary examination of the user behaviors involved in seeking and evaluating data is surprisingly absent from the research data discussion. This review explores the data retrieval literature to identify commonalities in how users search for and evaluate observational research data in selected disciplines. Two analytical frameworks, rooted in information retrieval and science and technology studies, are used to identify key similarities in practices as a first step toward developing a model describing data retrieval.</p>
  </span>
  
</div>
</li>
<li>

<div id="DBLP:conf/esws/GrothSDA19">
  
    <span class="title">End-to-End Learning for Answering Structured Queries Directly over
 Text</span>
    <span class="author">
      
        
          
            
              
                Paul T. Groth,
              
            
          
        
      
        
          
            
              
                Antony Scerri,
              
            
          
        
      
        
          
            
              
                Ron Daniel,
              
            
          
        
      
        
          
            
              
                and Bradley P. Allen
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Proceedings of the Workshop on Deep Learning for Knowledge Graphs
               (DL4KG2019) Co-located with the 16th Extended Semantic Web Conference
 2019 (ESWC 2019), Portoroz, Slovenia, June 2, 2019.</em>
    
    
      2019
    
    </span>
  

  <span class="links">
  
  
    [<a href="http://arxiv.org/abs/1811.06303" target="_blank">arXiv</a>]
  
  
  
  
    [<a href="http://ceur-ws.org/Vol-2377/paper_7.pdf" target="_blank">Link</a>]
  
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
</ol>

<h3 class="year">2018</h3>
<ol class="bibliography">
<li>

<div id="DBLP:conf/coling/GrothLSD18">
  
    <span class="title">Open Information Extraction on Scientific Text: An Evaluation</span>
    <span class="author">
      
        
          
            
              
                Paul T. Groth,
              
            
          
        
      
        
          
            
              
                Michael Lauruhn,
              
            
          
        
      
        
          
            
              
                Antony Scerri,
              
            
          
        
      
        
          
            
              
                and Ron Daniel
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Proceedings of the 27th International Conference on Computational
 Linguistics, COLING 2018, Santa Fe, New Mexico, USA, August 20-26,
 2018</em>
    
    
      2018
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="https://aclanthology.info/papers/C18-1289/c18-1289" target="_blank">Link</a>]
  
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="DBLP:conf/semweb/DeJongBDHMOSSST18">
  
    <span class="title">Elsevier’s Healthcare Knowledge Graph and the Case for Enterprise
 Level Linked Data Standards</span>
    <span class="author">
      
        
          
            
              
                Alex DeJong,
              
            
          
        
      
        
          
            
              
                Radmila Bord,
              
            
          
        
      
        
          
            
              
                Will Dowling,
              
            
          
        
      
        
          
            
              
                Rinke Hoekstra,
              
            
          
        
      
        
          
            
              
                Ryan Moquin,
              
            
          
        
      
        
          
            
              
                Charlie O,
              
            
          
        
      
        
          
            
              
                Mevan Samarasinghe,
              
            
          
        
      
        
          
            
              
                Paul Snyder,
              
            
          
        
      
        
          
            
              
                Craig Stanley,
              
            
          
        
      
        
          
            
              
                Anna Tordai,
              
            
          
        
      
        
          
            
              
                Michael Trefry,
              
            
          
        
      
        
          
            
              
                and Paul T. Groth
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Proceedings of the ISWC 2018 Posters &amp; Demonstrations, Industry
 and Blue Sky Ideas Tracks co-located with 17th International Semantic
 Web Conference (ISWC 2018), Monterey, USA, October 8th - to - 12th,
 2018.</em>
    
    
      2018
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="http://ceur-ws.org/Vol-2180/paper-85.pdf" target="_blank">Link</a>]
  
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="DBLP:conf/semweb/LauruhnGHD18">
  
    <span class="title">Use of Internal Testing Data to Help Determine Compensation for Crowdsourcing
 Tasks</span>
    <span class="author">
      
        
          
            
              
                Michael Lauruhn,
              
            
          
        
      
        
          
            
              
                Paul T. Groth,
              
            
          
        
      
        
          
            
              
                Corey A. Harper,
              
            
          
        
      
        
          
            
              
                and Helena F. Deus
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Proceedings of the 2nd International Workshop on Augmenting Intelligence
 with Humans\--in-\-the-\-Loop co-located with 17th International
 Semantic Web Conference (ISWC 2018), Monterey, California, October
 9th, 2018.</em>
    
    
      2018
    
    </span>
  

  <span class="links">
  
  
  
  
  
    [<a href="http://ceur-ws.org/Vol-2169/paper-04.pdf" target="_blank">Link</a>]
  
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
</ol>



  </article>

  

  

</div>

      </div>
    </div>

    <footer>

  <div class="wrapper">
    © Copyright 2025 INDE lab.
    
    

  </div>

</footer>


    <!-- Load jQuery -->
<script src="//code.jquery.com/jquery-1.12.4.min.js"></script>

<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>





<!-- Include custom icon fonts -->
<link rel="stylesheet" href="/assets/css/fontawesome-all.min.css">
<link rel="stylesheet" href="/assets/css/academicons.min.css">

<!-- Google Analytics -->
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', '', 'auto');
ga('send', 'pageview');
</script>


  </body>

</html>
